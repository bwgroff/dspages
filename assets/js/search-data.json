{
  
    
        "post0": {
            "title": "A Continuous Change-Point Model",
            "content": "using Turing using Bijectors using Gadfly using DataFrames, DataFramesMeta using StatsPlots Gadfly.set_default_plot_size(900px, 300px) . . Changepoint models are those in which an underlying process exhibits a discrete change in its behavior partway through your data. In other words, you have a specific point at which the behavior before and after differ in some material way. As an example, consider the following data taken from this post on the Julia discourse: . τ_true, μ₁, μ₂, σ_true = 500, 45, 30, 4 c = vcat(rand(Normal(μ₁,σ_true), τ_true), rand(Normal(μ₂,σ_true), 1000-τ_true)); Gadfly.plot(DataFrame(y=c, x=1:1000), x=:x, y=:y, Geom.line) . x -1500 -1000 -500 0 500 1000 1500 2000 2500 -1000 -950 -900 -850 -800 -750 -700 -650 -600 -550 -500 -450 -400 -350 -300 -250 -200 -150 -100 -50 0 50 100 150 200 250 300 350 400 450 500 550 600 650 700 750 800 850 900 950 1000 1050 1100 1150 1200 1250 1300 1350 1400 1450 1500 1550 1600 1650 1700 1750 1800 1850 1900 1950 2000 -1000 0 1000 2000 -1000 -900 -800 -700 -600 -500 -400 -300 -200 -100 0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 h,j,k,l,arrows,drag to pan i,o,+,-,scroll,shift-drag to zoom r,dbl-click to reset c for coordinates ? for help ? -70 -60 -50 -40 -30 -20 -10 0 10 20 30 40 50 60 70 80 90 100 110 120 130 -60 -58 -56 -54 -52 -50 -48 -46 -44 -42 -40 -38 -36 -34 -32 -30 -28 -26 -24 -22 -20 -18 -16 -14 -12 -10 -8 -6 -4 -2 0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114 116 118 120 -100 0 100 200 -60 -55 -50 -45 -40 -35 -30 -25 -20 -15 -10 -5 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 y Creating a model for this can be tricky, not least because MCMC and especially HMC :heart: differentiable (ie continuous!) variables, and the changepoint is discrete in the simplest implementation: . $$ begin{aligned} tau &amp; sim mathrm{DiscreteUniform}(1, mathrm{length}( mathcal{D})) mu_1, mu_2 &amp; sim mathrm{Normal}( mu_0, sigma_0) d_i &amp; sim begin{cases} mathrm{Normal}( mu_1, sigma) &amp; i leq tau mathrm{Normal}( mu_2, sigma) &amp; i &gt; tau end{cases} end{aligned} $$From the title of the post, you might have inferred that we don&#39;t need to have a discrete signal. Here&#39;s the core idea laid out on Gelman&#39;s blog: . The other thing I think you can do is a basis expansion in a basis that includes functions like -C/(1+exp(-(x-k)/a) (ie. a shifted rescaled sigmoid), put priors on the location for the shift and the degree of the shift (C) and the quickness of the shift (a)… There’s something to be said for approximating things as step functions, and there’s also something to be said for approximating things as infinitely smooth approximations to step functions :-)getting outside the rigidity of your model and thinking about approximations to your model can be helpful. . To create a smooth approximation, we look to a scaled, shifted version of the sigmoid function: . $$ begin{aligned} mathrm{sigmoid}(x) &amp;= frac{e^x}{1+e^x} l(a, b, x) &amp;= a(x-b) mathrm{sigm}(a, b, x) &amp;= mathrm{sigmoid} circ l(a,b,x) end{aligned} $$I think of $a$ as the &quot;specificity&quot; of the step change, and call it &quot;spec&quot; below. Perhaps naming isn&#39;t my strong suit. In any case... . logit = bijector(Beta()) # bijection: (0, 1) → ℝ inv_logit = inv(logit) # bijection: ℝ → (0, 1) function sigm(μ, σ, x) return inv_logit(σ*(x - μ)) end; x=-10:.1:20 df = DataFrame(y=sigm.(10, .5, x), x=x) Gadfly.plot(df, x=:x, y=:y, Geom.line) . x -50 -40 -30 -20 -10 0 10 20 30 40 50 60 -40 -39 -38 -37 -36 -35 -34 -33 -32 -31 -30 -29 -28 -27 -26 -25 -24 -23 -22 -21 -20 -19 -18 -17 -16 -15 -14 -13 -12 -11 -10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 -50 0 50 -40 -38 -36 -34 -32 -30 -28 -26 -24 -22 -20 -18 -16 -14 -12 -10 -8 -6 -4 -2 0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 h,j,k,l,arrows,drag to pan i,o,+,-,scroll,shift-drag to zoom r,dbl-click to reset c for coordinates ? for help ? -1.5 -1.0 -0.5 0.0 0.5 1.0 1.5 2.0 2.5 -1.00 -0.95 -0.90 -0.85 -0.80 -0.75 -0.70 -0.65 -0.60 -0.55 -0.50 -0.45 -0.40 -0.35 -0.30 -0.25 -0.20 -0.15 -0.10 -0.05 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 1.05 1.10 1.15 1.20 1.25 1.30 1.35 1.40 1.45 1.50 1.55 1.60 1.65 1.70 1.75 1.80 1.85 1.90 1.95 2.00 -1 0 1 2 -1.0 -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.0 y See? It&#39;s a smooth step function! That means we&#39;ll get gradients galore! We use that to interpolate between the two likelihoods we want to step between: . $$ begin{aligned} tau &amp; sim mathrm{Uniform}(1, mathrm{length}( mathcal{D})) mu_1, mu_2 &amp; sim mathrm{Normal}( mu_0, sigma_0) sigma &amp; sim mathrm{HalfNormal}(0, 10) zeta_i &amp;= mathrm{sigm}(a, tau, i) d_i &amp; sim mathrm{Normal}((1 - zeta_i) mu_1 + zeta_i mu_2, sigma) end{aligned} $$In Turing: . @model function changepoint(data) # priors spec = 0.01 μ_1 ~ Normal(0, 2) μ_2 ~ Normal(0, 2) τ ~ Uniform(1, 1000) σ ~ truncated(Normal(1, 2), 0, 20) # likelihood for i in 1:length(data) switch = sigm(τ, spec, i) z = (1-switch) * μ_1 + switch * μ_2 data[i] ~ Normal(z, σ) end end; . Now we&#39;re ready to roll - I had to fuss with both $ epsilon$ and spec before landing on standardizing the data as the most important first step, so you may find better hyperparameter values. . std_c = (c .- mean(c)) ./ std(c); # Settings of the Hamiltonian Monte Carlo (HMC) sampler. iterations = 500 ϵ = 0.005 τ = 10; cp_chain2 = sample( changepoint(std_c), HMC(ϵ, τ), iterations, progress=true, drop_warmup=false); . Sampling: 100%|█████████████████████████████████████████| Time: 0:00:10 . StatsPlots.plot(cp_chain2, size=(3500,2200), titlefont = (34), tickfont=(18), guide=&quot;&quot;) . . :tada: Voilà! :tada: .",
            "url": "http://www.bwg.is/julia/turing/changepoint/2021/01/19/Changepoint-Models.html",
            "relUrl": "/julia/turing/changepoint/2021/01/19/Changepoint-Models.html",
            "date": " • Jan 19, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "A Classic from David MacKay",
            "content": "A classic textbook in information theory is Information Theory, by David MacKay. When I was first starting out, I came across this book (it is, after all, free - graduate students rejoice!) and I really enjoyed his exposition on p. 48 about &quot;a first inference problem.&quot; I recommend reading it if you haven&#39;t, it&#39;s great. . Anyway, I&#39;ve reproduced the problem here and I&#39;ll share a Turing solution below. . . The trickiness comes from the window which truncates the data. This is actually super easy to accomplish in Stan, Turing, etc with basically single line changes to the most natural model. . using Turing using Bijectors using Gadfly using DataFrames, DataFramesMeta #using Zygote #Turing.setadbackend(:zygote) Gadfly.set_default_plot_size(900px, 300px) . . Here&#39;s how things look in the simpler case where there is no truncation. . $$ begin{aligned} lambda &amp; sim mathrm{Uniform}(0, N) d_i &amp; sim mathrm{Exponential}( lambda) end{aligned}$$And some data to match: . λ_true = 12.0 data = rand(Exponential(λ_true), 500) plot(DataFrame(x=data),x=:x, xintercept=[20], Geom.histogram, Geom.vline(color=&quot;red&quot;), Coord.cartesian(xmin=0.0, ymin=0.0), Guide.yticks(label = false)) . x -70 -60 -50 -40 -30 -20 -10 0 10 20 30 40 50 60 70 80 90 100 110 120 130 -58 -56 -54 -52 -50 -48 -46 -44 -42 -40 -38 -36 -34 -32 -30 -28 -26 -24 -22 -20 -18 -16 -14 -12 -10 -8 -6 -4 -2 0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114 -100 0 100 200 -60 -55 -50 -45 -40 -35 -30 -25 -20 -15 -10 -5 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 h,j,k,l,arrows,drag to pan i,o,+,-,scroll,shift-drag to zoom r,dbl-click to reset c for coordinates ? for help ? You can see that even though $ lambda_{true} = 12 &lt; 20$ the window (red) would still truncate quite a bit of the data in the original problem description. Here&#39;s the model written out in Turing: . @model function decay_estimator(decays::Array{Float64}) λ ~ Uniform(0, 30) decays ~ filldist(Exponential(λ), length(decays)) end; . . Note: The filldist function is a way to avoid looping over the decays array. It populates a matching array of random variables so we have something like Array{Float64} ~ Array{Distribution}. In other words, it allows something like element-wise sampling for iid variables. . iterations = 2000 ϵ = 0.02 τ = 10; λ_chain = sample( decay_estimator(data), HMC(ϵ, τ), iterations, progress=true, drop_warmup=true); . Sampling: 100%|█████████████████████████████████████████| Time: 0:00:01 . plot(DataFrame(λ_chain), x=:λ, xintercept=[λ_true], Theme(alphas=[0.6]), Geom.density, Geom.vline(color=&quot;green&quot;), Coord.cartesian(ymin=0.0), Guide.yticks(label = false)) . . λ 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0 6.5 7.0 7.5 8.0 8.5 9.0 9.5 10.0 10.5 11.0 11.5 12.0 12.5 13.0 13.5 14.0 14.5 15.0 15.5 16.0 16.5 17.0 17.5 18.0 18.5 19.0 19.5 20.0 20.5 21.0 0 10 20 30 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0 6.5 7.0 7.5 8.0 8.5 9.0 9.5 10.0 10.5 11.0 11.5 12.0 12.5 13.0 13.5 14.0 14.5 15.0 15.5 16.0 16.5 17.0 17.5 18.0 18.5 19.0 19.5 20.0 20.5 21.0 h,j,k,l,arrows,drag to pan i,o,+,-,scroll,shift-drag to zoom r,dbl-click to reset c for coordinates ? for help ? Well this model pretty much nails it. The original value of $ lambda_{true}$ was 12 and that peak is right on the money. Let&#39;s try the same model with truncated data... :grimacing:! . data_trunc = [d for d in data if d &lt;= 20.0] plot(DataFrame(x=data_trunc),x=:x, xintercept=[20], Theme(alphas=[0.6]), Geom.histogram, Geom.vline(color=&quot;red&quot;), Coord.cartesian(xmin=0.0, ymin=0.0), Guide.yticks(label = false)) . x -25 -20 -15 -10 -5 0 5 10 15 20 25 30 35 40 45 -20 -19 -18 -17 -16 -15 -14 -13 -12 -11 -10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 -20 0 20 40 -20 -18 -16 -14 -12 -10 -8 -6 -4 -2 0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 h,j,k,l,arrows,drag to pan i,o,+,-,scroll,shift-drag to zoom r,dbl-click to reset c for coordinates ? for help ? λ_trunc_chain = sample( decay_estimator(data_trunc), HMC(ϵ, τ), iterations, progress=false, drop_warmup=true); . trunc_df = @where(DataFrame(λ_trunc_chain), :λ .&lt; 50) plot(trunc_df, x=:λ, xintercept=[λ_true], Theme(alphas=[0.6]), Geom.density, Geom.vline(color=&quot;green&quot;), Coord.cartesian(xmin=0.0, ymin=0.0), Guide.yticks(label = false)) . . λ -14 -12 -10 -8 -6 -4 -2 0 2 4 6 8 10 12 14 16 18 20 22 24 26 -12.0 -11.5 -11.0 -10.5 -10.0 -9.5 -9.0 -8.5 -8.0 -7.5 -7.0 -6.5 -6.0 -5.5 -5.0 -4.5 -4.0 -3.5 -3.0 -2.5 -2.0 -1.5 -1.0 -0.5 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0 6.5 7.0 7.5 8.0 8.5 9.0 9.5 10.0 10.5 11.0 11.5 12.0 12.5 13.0 13.5 14.0 14.5 15.0 15.5 16.0 16.5 17.0 17.5 18.0 18.5 19.0 19.5 20.0 20.5 21.0 21.5 22.0 22.5 23.0 23.5 24.0 -20 0 20 40 -12 -11 -10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 h,j,k,l,arrows,drag to pan i,o,+,-,scroll,shift-drag to zoom r,dbl-click to reset c for coordinates ? for help ? That is most definitely not correct. So, we&#39;ll need a new model. . $$ begin{aligned} lambda &amp; sim mathrm{Uniform}(0, N) d_i &amp; sim mathrm{Exponential} vert_{0}^{20}( lambda) end{aligned}$$ . Note: I&#8217;m not aware of any specific notation for truncated distributions (and I spent like 3 whole minutes looking) so $ mathcal{D}|_{a}^{b}(x)$ seemed fine. . @model function decay_estimator_trunc(decays::Array{Float64}) λ ~ Uniform(0, 50) T = typeof(λ) for i in 1:length(decays) decays[i] ~ truncated(Exponential(λ), T(0.0), T(20.0)) #wtf end end; . You might be wondering what&#39;s the story with T. Good question! My understanding is that there&#39;s an issue in Distributions.jl where the truncated function ends up mixing up simple Number types (0.0 and 20.0 in this case) with Dual types (the types that track derivative information for auto-differentiation). There&#39;s a discussion on this open issue. Anyway, by explicitly casting the Number values as T (which is some Dual type we peeked from $ lambda$ here) we can make it work! . λ_trunc_correct_chain = sample( decay_estimator_trunc(data_trunc), HMC(ϵ, τ), iterations, progress=true, drop_warmup=true); plot(DataFrame(λ_trunc_correct_chain), x=:λ, xintercept=[λ_true], Theme(alphas=[0.6]), Geom.density, Geom.vline(color=&quot;green&quot;), Coord.cartesian(xmin=0.0, ymin=0.0), Guide.yticks(label = false)) . . Sampling: 100%|█████████████████████████████████████████| Time: 0:00:17 . λ -40 -30 -20 -10 0 10 20 30 40 50 60 70 -28 -27 -26 -25 -24 -23 -22 -21 -20 -19 -18 -17 -16 -15 -14 -13 -12 -11 -10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 -30 0 30 60 -28 -26 -24 -22 -20 -18 -16 -14 -12 -10 -8 -6 -4 -2 0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 h,j,k,l,arrows,drag to pan i,o,+,-,scroll,shift-drag to zoom r,dbl-click to reset c for coordinates ? for help ? Ahhhh! Much better :tada:! .",
            "url": "http://www.bwg.is/julia/turing/2021/01/15/A-Classic-Example.html",
            "relUrl": "/julia/turing/2021/01/15/A-Classic-Example.html",
            "date": " • Jan 15, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Customer LTV",
            "content": "using Turing using Gadfly using DataFrames, DataFramesMeta Gadfly.set_default_plot_size(900px, 300px) ENV[&quot;COLUMNS&quot;] = 120; . . . Warning: Still a draft (note the tragic lack of delightful visuals). . Customer Lifetime Value (LTV or CLTV) is the total dollar value a consumer will spend at a business throughout their life. The concept is as important as the definition is straightforward - businesses very often want to know which consumers are their whales and which are eating up their marketing or infrastructure budgets with little or no value returned. This is pretty tricky and there are a few approaches you can take: . Observational . Naive calculation. The following will give you an average that is delightfully simple but tragically wrong: . $$ mathrm{LTV} = frac{1}{| mathrm{Customers}|} sum_{ mathrm{orders}} mathrm{Order Value}$$ . Assuming (hmm) that LTV is constant over time, this will converge to the true average LTV value as customers churn (and thus achieve their final lifetime value). New customers will continue to weigh the average down and make it an underestimate. There are some of these sort of equations floating around the tubes. . Wait and see. Simialr algorithm to the above, the major difference is applying this to only a small cohort from a brief window in time. Just follow along with that group and add up how much they spend. This is simple and will get to the true LTV of that cohort faster but it&#39;s still typically too slow to be useful. By the time you know, it&#39;s months/quarters/years later (depending on the churn / repurchasing characteristics of your product) and most insights you might glean are no longer relevant to your product roadmap. . Modeled . Machine Learning :tada:. There are a bunch of ML approaches that can be found relatively easily online (but apparently not easy enough for me to find them again to include here). IIRC, one was using a random forest (or GBM, or whatever) to predict . $$P( mathrm{purchase in next period}| mathcal{D})$$ . and then in a second stage model (conditioned on the purchase outcome) predict the order value of said purchase. . It&#39;s a reasonably standard approach: decompose the problem into churn, expected future purchases, and expected value per purchase. There are a bunch of approaches that are tailored to this decomposition by breaking down the inputs into the so called RFM metrics: . Recency: time since the last purchase, | Frequency: number of purchases per time period, | Monetary value: average order value. | . Note that we&#39;ll use days for the time scale. . Buy &#39;til You Die. This type of model was popularized by Schmittlein, David C., Donald G. Morrison, and Richard Colombo in 1987 but was apparently not very easy to implement. A simpler version was created by Fader, Hardie and Lee and Fader at least built a company that expanded quite a bit on these sorts of models, Zodiac. . Custom Model. That&#39;s what we&#39;re going to do! Fader and Hardie do a great job of making their work look harder than necessary so I can&#39;t be bothered to decode it (and anyway, Alex did a great job). That said, I&#39;m going to take what seems to be a similar approach and takes advantage of some more modern techniques (Julia and Turing.jl!): . Estimate churn based on Recency and Frequency. | Set up a super simple survival model to understand the expected number of future purchases using sample from (1) as the churn signal. | Scale by Monetary value. | By building these submodels out independently we can understood the whole model by figuring it out component-by-component. It also provides a quick way to make single-component adjustments that might be important. There will be many, this model has some real obvious deficiencies even though it captures the right ideas. . For instance, some retailers have an extremely wide spread of possible order values (e.g. Walmart, you can buy a stick of gum or probably a boat or something). If there are orders-of-magnitude differences in purchase value then you better model that out so you know exactly which consumers are likely to find themselves in that lucrative long tail. In my experience, lognormal is a decent start but the tail is still too light. . Our Models . Active from RF . We sample when we expect the customer&#39;s next purchase to occur based on what we&#39;ve observed of their frequency, then we compare that to how long it&#39;s been since they purchased. If we expected them to have purchased already but they haven&#39;t then we count them as churned. . $$ begin{aligned} mathrm{next purchase} &amp; sim mathrm{Exponential}(F) mathrm{active} &amp;= R &lt; mathrm{next purchase} end{aligned} $$Note that we don&#39;t have any kind of regularization and just assume F is a fine number for us. Exercise for the reader to make that more stable :smile:. And also, what should we do about customers with only 1 purchase? :scream: . Future Purchases from RF+Active . We&#39;d like to then take the inferences above and use them to understand churn as a function of time, or perhaps number of orders. In other words: . $$P( mathrm{churned}_{t=i} | mathrm{active}_{t=i-1})$$ . Here we find some wrinkles. Most notably, what to do with consumers that have recently purchased and we don&#39;t know if they are going to churn before the next purchase? This is called censoring, which comes in many directional varieties and this variety is called right-censoring (on the &quot;right&quot; side of our time interval, we don&#39;t yet have data on the outcome). We&#39;ll ignore that for now, and instead assume &quot;constant hazard&quot; on the data we can observe, ie the rate at which users remain active ($ rho$) is constant across all time points. . $$ begin{aligned} rho &amp; sim mathrm{Beta}(1,1) mathrm{purchases}_{uncensored} &amp; sim mathrm{Geometric( rho)} ( mathrm{Future purchases}) &amp; sim begin{cases} mathrm{Geometric}( rho) &amp; mathrm{if active} mathrm{Dirac}(0) &amp; mathrm{otherwise} end{cases} end{aligned} $$LTV from M+Future Purchases . $$ begin{aligned} mathrm{Future value} &amp;= mathrm{Future purchases} * mathrm{AOV} mathrm{Lifetime value} &amp;= mathrm{Future value} + mathrm{Past value} end{aligned} $$ Setting up some Daaaataaa . A little toy dataset to see if the Active model makes any kind of sense. . struct CustomerData days_since_last_purchase::Int64 days_since_first_purchase::Int64 total_purchases::Int64 monetary_value::Float64 end struct RFM raw::CustomerData recency::Int64 frequency::Float64 monetary_value::Float64 total_purchases::Int64 end function rfm(c::CustomerData) active_days = c.days_since_first_purchase - c.days_since_last_purchase period = (active_days) / (c.total_purchases - 1) # wcgw? rfm = RFM( c, c.days_since_last_purchase, 1 / period, c.monetary_value, c.total_purchases) end; . rfm_data = [rfm(c) for c in [ CustomerData(2, 60, 5, 3), CustomerData(10, 305, 10, 23), CustomerData(53, 100, 40, 123), # definitely churned! CustomerData(2, 29, 3, 123), CustomerData(10, 200, 5, 23), CustomerData(23, 222, 20, 3), # probably churned.. ]]; . Active Model . @model function active(custs::Array{RFM}) predicted_purchase_days = Vector(undef, length(custs)) active = Vector{Bool}(undef, length(custs)) for i in 1:length(custs) predicted_purchase_days[i] ~ Exponential(1.0 / custs[i].frequency) active[i] = predicted_purchase_days[i] &gt; custs[i].recency end return active end; . iterations = 1000 ϵ = 0.05 τ = 10; chain_ltv = sample( active(rfm_data), HMC(ϵ, τ), iterations, progress=false, drop_warmup=true); . . Let&#39;s see how the model&#39;s output matches up with our expectations: . active_samples = DataFrame(hcat(generated_quantities(active(rfm_data), chain_ltv)...)&#39;) combine(active_samples, :x1 =&gt; mean, :x2 =&gt; mean, :x3 =&gt; mean, :x4 =&gt; mean, :x5 =&gt; mean, :x6 =&gt; mean) . x1_meanx2_meanx3_meanx4_meanx5_meanx6_mean . Float64Float64Float64Float64Float64Float64 . 1 rows × 6 columns . 10.891 | 0.675 | 0.0 | 0.943 | 0.779 | 0.111 | . Here, x1_mean is the probability that the first customer is still active. These numbers look pretty reasonable to me, even though we didn&#39;t account for any uncertainty around F (or, like, what to do with customers that only purchased 1 time... alas). . Notice that I used generated_quantities here. This is possible because we have return active in the model block. The Turing handling of generated quantities is... just ok, sort of awkward to work with. :grimacing: . And with the CDNow dataset... . The raw data can be found here and represents a cohort of users that made their first purchase at CDNow in Q1 of 1997. . using CSV cdnow = CSV.read(&quot;/Users/brad/data/cleaned_cdnow.csv&quot;, DataFrame) # oh no now you know where my filez first(cdnow, 5) . . customerdatecountusd . Int64Date…Int64Float64 . 5 rows × 4 columns . 11 | 1997-01-01 | 1 | 11.77 | . 22 | 1997-01-12 | 1 | 12.0 | . 32 | 1997-01-12 | 5 | 77.0 | . 43 | 1997-01-02 | 2 | 20.76 | . 53 | 1997-03-30 | 2 | 20.76 | . We also need to get it a little closer to RFM format, which gives us the following table: . using Dates cutoff_date = Date(&quot;1997-04-01&quot;) cdnow_gdf = @linq cdnow |&gt; where(:date .&lt; cutoff_date) |&gt; groupby(:customer) pre_rfm = combine(cdnow_gdf, nrow =&gt; :total_purchases, :date =&gt; minimum =&gt; :first_purchase_dt, :date =&gt; maximum =&gt; :latest_purchase_dt, :usd =&gt; sum =&gt; :monetary_value) function days_val(days) return days.value end rfm_df = @linq pre_rfm |&gt; transform( days_since_first_purchase = days_val.(cutoff_date - :first_purchase_dt), days_since_last_purchase = days_val.(cutoff_date - :latest_purchase_dt) ) first(rfm_df, 5) . . customertotal_purchasesfirst_purchase_dtlatest_purchase_dtmonetary_valuedays_since_first_purchasedays_since_last_purchase . Int64Int64DateDateFloat64Int64Int64 . 5 rows × 7 columns . 11 | 1 | 1997-01-01 | 1997-01-01 | 11.77 | 90 | 90 | . 22 | 2 | 1997-01-12 | 1997-01-12 | 89.0 | 79 | 79 | . 33 | 2 | 1997-01-02 | 1997-03-30 | 41.52 | 89 | 2 | . 44 | 2 | 1997-01-01 | 1997-01-18 | 59.06 | 90 | 73 | . 55 | 3 | 1997-01-01 | 1997-02-04 | 82.2 | 90 | 56 | . Which we can blast into RFM format. The model requires some tiny adjustments because in this dataset we have: . Customers with only one purchase, | Customers with only one purchase date but multiple purchases | . rfm_cdn = [ rfm( CustomerData( row.days_since_last_purchase, row.days_since_first_purchase, row.total_purchases, row.monetary_value) ) for row in eachrow(rfm_df)]; . . @model function active_cdn(custs::Array{RFM}) predicted_purchase_days = Vector(undef, length(custs)) active = Vector{Bool}(undef, length(custs)) for i in 1:length(custs) if isnan(custs[i].frequency) | isinf(custs[i].frequency) predicted_purchase_days[i] ~ Exponential(15.0) # median period for multiple purchasers else predicted_purchase_days[i] ~ Exponential(1.0 / custs[i].frequency) end active[i] = predicted_purchase_days[i] &gt; custs[i].recency end return active end; . chain_ltv_cdn = sample( active_cdn(rfm_cdn[1:100]), HMC(ϵ, τ), iterations, progress=true, drop_warmup=true); . Sampling: 100%|█████████████████████████████████████████| Time: 0:00:24 . So yeah, it&#39;s on the slow side.. well not slow given how much cool stuff is happening. There are like 20k customers in this dataset and only the first 100 took 30s. . Future Purchases and LTV Model . @model function future_purchases_cdn(custs::Array{RFM}, total_purchases::Array{Float64}) # Active submodel predicted_purchase_days = Vector(undef, length(custs)) active = Vector{Bool}(undef, length(custs)) for i in 1:length(custs) if isnan(custs[i].frequency) | isinf(custs[i].frequency) predicted_purchase_days[i] ~ Exponential(15.0) # median period for multiple purchasers else predicted_purchase_days[i] ~ Exponential(1.0 / custs[i].frequency) end active[i] = predicted_purchase_days[i] &gt; custs[i].recency end # Future purchases submodel churn_rate ~ Beta(1,1) future_purchases = Vector(undef, length(custs)) for i in 1:length(custs) if !active[i] total_purchases[i] ~ Exponential(churn_rate) future_purchases[i] ~ Exponential(1e-3) # Turing fails without this ^ because I lazily didn&#39;t declare a prior # and if not active the right answer is 0 so... # we&#39;ll clean it up in post ;) else future_purchases[i] ~ Exponential(churn_rate) end end # LTV &quot;model&quot; ltv = future_purchases .* [c.monetary_value for c in custs] return active, ltv end; . total_purchases = [float(r.total_purchases) for r in rfm_cdn] chain_future_purchases = sample( future_purchases_cdn(rfm_cdn[1:100], total_purchases[1:100]), HMC(ϵ, τ), iterations, progress=true, drop_warmup=true); . Sampling: 100%|█████████████████████████████████████████| Time: 0:02:17 . So there&#39;s the model! Unfortunately, wrangling generated_quantities can be annoying so making nice plots will have to wait (more to come!). .",
            "url": "http://www.bwg.is/julia/turing/churn/survival/ltv/2021/01/14/LTV.html",
            "relUrl": "/julia/turing/churn/survival/ltv/2021/01/14/LTV.html",
            "date": " • Jan 14, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Item Response Models",
            "content": ". Important: This is just a draft! I haven&#8217;t 1) finished creating reasonable data sets for each model or 2) made even one pretty picture! You&#8217;re stuck with the chain summaries for now :dizzy_face:! . using Turing using Bijectors using Gadfly using DataFrames, DataFramesMeta Gadfly.set_default_plot_size(900px, 300px) . . Item Response . Item response models are used to simultaneously make inferences about two interacting populations. Commonly, a population of test questions and a population of test takers (students) with the result (success/failure) of each student on each question they&#39;ve seen. This is an interesting problem in that even in the basic case: . students have different levels of aptitude | questions have different levels of difficulty | not every student sees every question | not every question needs to be seen by the same number of students | we should be able to make relative inferences between students (resp. questions) that have no overlapping questions (resp. students) | the data is nonetheless fairly simple: [correct (Boolean), student_id (categorical), question_id (categorical] | . I love these models because they&#39;re easy to extend in an intuitive way. I&#39;m going to add a few random bells and whistles to the most vanilla version, and if you&#39;re interested the Stan user guide has some good content on this topic and many others. . Some IRT Models . Vanilla Item-Response (aka 1PL) . For each student $s$, we have an aptitude $ alpha_s$ and for each question $q$ we have a difficulty $ gamma_q$. The likelihood of a correct response is informed by the difference between these two quantities: . $$ begin{aligned} alpha_s &amp; sim mathrm{Normal}(0,5) gamma_q &amp; sim mathrm{Normal}(0,5) beta_{s, q} &amp;= mathrm{logit}^{-1}( alpha_s - gamma_q) mathrm{correct_{s,q}} &amp; sim mathrm{Bernoulli}( beta_{s,q}) end{aligned}$$ logit = bijector(Beta()) # bijection: (0, 1) → ℝ inv_logit = inv(logit) # bijection: ℝ → (0, 1) student = [1,1,1,1,2,2,2,2,3,3,3,3] question = [1,2,3,4,2,3,4,5,3,4,5,1] correct = [ true, true, true, false, true, false, false, true, false, false, false, true]; . Some observations on the toy data: . Everyone got question 1 correct (expect this to be rated as low difficulty) | Everyone got question 4 wrong (high difficulty) | Student 1 got all tested questions correct except question 4 | Student 3 got all tested questions incorrect except question 1 | Question 5 was only seen by student 3 (incorrect) | . So, here&#39;s the model set up in Turing, and the result of the sampler below. . @model function irt_1pl(correct::Array{Bool}, student::Array{Int64}, question::Array{Int64}) aptitude = Vector(undef, maximum(student)) difficulty = Vector(undef, maximum(question)) # priors for i in 1:length(aptitude) aptitude[i] ~ Normal(0,5) end for i in 1:length(difficulty) difficulty[i] ~ Normal(0,5) end β = Vector(undef, length(correct)) for i in 1:length(correct) β[i] = aptitude[student[i]] - difficulty[question[i]] correct[i] ~ Bernoulli(inv_logit(β[i])) end end; # Settings of the Hamiltonian Monte Carlo (HMC) sampler. iterations = 1000 ϵ = 0.05 τ = 10; irt_1pl_ch = sample( irt_1pl(correct, student, question), HMC(ϵ, τ), iterations, progress=true, drop_warmup=true) . Sampling: 100%|█████████████████████████████████████████| Time: 0:00:00 . Chains MCMC chain (1000×17×1 Array{Float64,3}): Iterations = 1:1000 Thinning interval = 1 Chains = 1 Samples per chain = 1000 parameters = aptitude[1], aptitude[2], aptitude[3], difficulty[1], difficulty[2], difficulty[3], difficulty[4], difficulty[5] internals = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, n_steps, nom_step_size, step_size Summary Statistics parameters mean std naive_se mcse ess rhat Symbol Float64 Float64 Float64 Float64 Float64 Float64 aptitude[1] 3.2740 1.9350 0.0612 0.3207 22.7341 1.0402 aptitude[2] 0.9977 2.2009 0.0696 0.5345 5.0679 1.2607 aptitude[3] -2.7975 3.1851 0.1007 0.9097 3.2885 1.5668 difficulty[1] -6.6429 4.3688 0.1382 1.3718 2.4382 2.1207 difficulty[2] -3.1028 2.2644 0.0716 0.5146 13.6893 1.0655 difficulty[3] 2.0820 2.0146 0.0637 0.4029 10.0855 1.1187 difficulty[4] 5.3785 2.3564 0.0745 0.6279 10.9535 1.0266 difficulty[5] -0.7591 3.7529 0.1187 1.0978 3.7110 1.4890 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% Symbol Float64 Float64 Float64 Float64 Float64 aptitude[1] 0.1558 1.7989 3.0630 4.7257 6.9881 aptitude[2] -2.7293 -0.6033 0.8091 2.4061 5.2246 aptitude[3] -9.5331 -4.5425 -2.9342 -0.7317 2.7270 difficulty[1] -12.9759 -10.1684 -7.3905 -3.1434 2.1283 difficulty[2] -9.1851 -4.3815 -2.6233 -1.5957 0.3462 difficulty[3] -2.0318 0.6111 2.2832 3.5960 5.3615 difficulty[4] 1.1812 3.6750 5.2200 6.9466 10.4091 difficulty[5] -7.9556 -2.9220 -1.3910 1.0610 8.3417 . Interesting, the only surprise for me is that I expected a wider spread for difficulty[5], but otherwise looks very reasonable! . Question Quality (aka 2PL) . The purpose of asking questions is to probe the aptitude of the test taker, and some questions will do a much better job of guaranteeing a minimum skill level given a successful response. This is called &quot;discrimination&quot;. Intuitively, a highly discriminating question would magnify the difference between a student&#39;s ability and the question&#39;s difficulty, so that both . students with sufficient aptitude are more likely to succeed | students with insufficient aptitude are more likely to fail | . We can see that $ eta$ will accomplish this in the model below: . $$ begin{aligned} alpha_s &amp; sim mathrm{Normal}(0,5) gamma_q &amp; sim mathrm{Normal}(0,5) eta_q &amp; sim mathrm{LogNormal}(0,2) beta_{s, q} &amp;= mathrm{logit}^{-1}( eta_q * ( alpha_s - gamma_q)) mathrm{correct_{s,q}} &amp; sim mathrm{Bernoulli}( beta_{s,q}) end{aligned}$$ @model function irt_2pl(correct::Array{Bool}, student::Array{Int64}, question::Array{Int64}) aptitude = Vector(undef, maximum(student)) difficulty = Vector(undef, maximum(question)) discr = Vector(undef, maximum(question)) # priors for i in 1:length(aptitude) aptitude[i] ~ Normal(0,5) end for i in 1:length(difficulty) difficulty[i] ~ Normal(0,5) end for i in 1:length(difficulty) discr[i] ~ LogNormal(0,2) end β = Vector(undef, length(correct)) for i in 1:length(correct) β[i] = discr[question[i]] * (aptitude[student[i]] - difficulty[question[i]]) correct[i] ~ Bernoulli(inv_logit(β[i])) end end; . irt_2pl_ch = sample( irt_2pl(correct, student, question), HMC(ϵ, τ), iterations, progress=true, drop_warmup=true) . . Sampling: 37%|███████████████▏ | ETA: 0:00:02┌ Warning: The current proposal will be rejected due to numerical error(s). │ isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false) └ @ AdvancedHMC /Users/brad/.julia/packages/AdvancedHMC/MIxdK/src/hamiltonian.jl:47 Sampling: 38%|███████████████▋ | ETA: 0:00:02┌ Warning: The current proposal will be rejected due to numerical error(s). │ isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false) └ @ AdvancedHMC /Users/brad/.julia/packages/AdvancedHMC/MIxdK/src/hamiltonian.jl:47 Sampling: 100%|█████████████████████████████████████████| Time: 0:00:03 . Chains MCMC chain (1000×22×1 Array{Float64,3}): Iterations = 1:1000 Thinning interval = 1 Chains = 1 Samples per chain = 1000 parameters = aptitude[1], aptitude[2], aptitude[3], difficulty[1], difficulty[2], difficulty[3], difficulty[4], difficulty[5], discr[1], discr[2], discr[3], discr[4], discr[5] internals = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, n_steps, nom_step_size, step_size Summary Statistics parameters mean std naive_se mcse ess rhat Symbol Float64 Float64 Float64 Float64 Float64 Float64 aptitude[1] 1.2991 2.5842 0.0817 0.6109 15.4744 1.0188 aptitude[2] -0.4991 2.5806 0.0816 0.7655 4.9059 1.1926 aptitude[3] -1.8909 3.3642 0.1064 0.9387 6.3762 1.1386 difficulty[1] -2.1490 3.1013 0.0981 0.8999 3.7623 1.3383 difficulty[2] -3.7273 1.9332 0.0611 0.4666 14.1960 1.0006 difficulty[3] -3.8600 4.1205 0.1303 1.2739 2.9892 1.7147 difficulty[4] 3.3615 2.0557 0.0650 0.4997 5.5086 1.3375 difficulty[5] -2.0982 3.6023 0.1139 1.0232 3.3308 1.5764 discr[1] 4.2717 13.8163 0.4369 2.4126 24.7575 1.0508 discr[2] 4.3264 11.0954 0.3509 1.7288 36.1833 1.0601 discr[3] 1.1143 3.4122 0.1079 0.6271 13.4357 1.0971 discr[4] 7.9696 12.9932 0.4109 1.7747 55.6834 1.0197 discr[5] 2.0524 4.9542 0.1567 0.8716 17.5768 1.0340 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% Symbol Float64 Float64 Float64 Float64 Float64 aptitude[1] -2.7132 -0.5813 0.8765 2.8893 7.2904 aptitude[2] -4.8826 -2.5355 -0.6822 1.5337 4.2364 aptitude[3] -8.0107 -4.8561 -1.1829 0.8619 3.2192 difficulty[1] -10.9402 -3.1502 -1.5466 -0.1949 2.7139 difficulty[2] -8.1221 -4.9271 -3.3535 -2.3146 -0.8306 difficulty[3] -11.1577 -7.2108 -3.4431 -0.7276 3.0153 difficulty[4] -1.2933 2.1900 3.4221 4.8106 6.8774 difficulty[5] -7.7892 -4.9410 -2.8640 0.7741 4.9000 discr[1] 0.0254 0.1579 0.6579 2.1601 36.1958 discr[2] 0.0213 0.3799 0.8490 2.7462 38.2713 discr[3] 0.0074 0.0353 0.0986 0.5403 8.5258 discr[4] 0.0623 0.5002 2.8361 10.1297 45.3600 discr[5] 0.0119 0.0991 0.2953 1.3438 16.8309 . Guessing Behavior . It&#39;s common knowledge that guessing is advantageous on the SATs if you can eliminate at least 1 answer. This is because there are usually 5 responses and an incorrect response is penalized by 1/4 point. In the previous examples we assumed that question difficulty and student aptitude accounted for a span of possible $P( mathrm{correct})$ covering $(0,1)$, but if the test taker can opportunistically guess (ie on a multiple choice test) then the true probabilities have some other lower bound, $( delta, 1), delta &gt; 0$. . Modifying our first model to account for this is relatively straightforward: . $$ begin{aligned} delta &amp; sim mathrm{Beta}(1, 2) alpha_s &amp; sim mathrm{Normal}(0,5) gamma_q &amp; sim mathrm{Normal}(0,5) beta_{s, q} &amp;= delta + (1- delta) mathrm{logit}^{-1}( alpha_s - gamma_q) mathrm{correct_{s,q}} &amp; sim mathrm{Bernoulli}( beta_{s,q}) end{aligned}$$ @model function irt_guess(correct::Array{Bool}, student::Array{Int64}, question::Array{Int64}) aptitude = Vector(undef, maximum(student)) difficulty = Vector(undef, maximum(question)) # priors for i in 1:length(aptitude) aptitude[i] ~ Normal(0,5) end for i in 1:length(difficulty) difficulty[i] ~ Normal(0,5) end guess_factor ~ Beta(1,2) β = Vector(undef, length(correct)) for i in 1:length(correct) β[i] = aptitude[student[i]] - difficulty[question[i]] correct[i] ~ Bernoulli(guess_factor + (1-guess_factor)*inv_logit(β[i])) end end; . irt_guess_ch = sample( irt_guess(correct, student, question), HMC(ϵ, τ), iterations, progress=true, drop_warmup=true) . . Sampling: 100%|█████████████████████████████████████████| Time: 0:00:00 . Chains MCMC chain (1000×18×1 Array{Float64,3}): Iterations = 1:1000 Thinning interval = 1 Chains = 1 Samples per chain = 1000 parameters = aptitude[1], aptitude[2], aptitude[3], difficulty[1], difficulty[2], difficulty[3], difficulty[4], difficulty[5], guess_factor internals = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, n_steps, nom_step_size, step_size Summary Statistics parameters mean std naive_se mcse ess rhat Symbol Float64 Float64 Float64 Float64 Float64 Float64 aptitude[1] 2.4869 2.5707 0.0813 0.7223 3.2350 1.6621 aptitude[2] 0.0467 2.1501 0.0680 0.4649 4.9934 1.3398 aptitude[3] -4.6788 2.3852 0.0754 0.5883 12.5814 1.0098 difficulty[1] -5.4882 3.0988 0.0980 0.7927 11.2340 1.0712 difficulty[2] -1.3732 1.8141 0.0574 0.3498 12.9492 1.1089 difficulty[3] 2.2928 3.9825 0.1259 1.2095 2.8536 1.6963 difficulty[4] 5.0951 1.9785 0.0626 0.4414 5.7468 1.2786 difficulty[5] -0.9364 2.5749 0.0814 0.6004 17.2439 0.9997 guess_factor 0.2061 0.1453 0.0046 0.0167 49.5365 0.9990 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% Symbol Float64 Float64 Float64 Float64 Float64 aptitude[1] -2.7677 0.6181 2.6535 4.2176 7.0921 aptitude[2] -4.4554 -1.3947 0.2112 1.5970 3.9855 aptitude[3] -9.1785 -6.4195 -4.4813 -2.8343 -0.2408 difficulty[1] -10.9864 -7.4053 -5.9243 -3.7231 2.0833 difficulty[2] -5.1880 -2.6083 -1.2140 0.0306 1.6720 difficulty[3] -3.9818 -0.5712 1.5472 3.9268 11.2302 difficulty[4] 1.4102 3.7990 5.0364 6.2808 9.6207 difficulty[5] -7.2441 -2.3121 -0.8704 0.7449 3.9909 guess_factor 0.0136 0.0825 0.1808 0.3095 0.5229 . Two Kinds of Questions . Students aren&#39;t universally adept at answering questions of different types, so let&#39;s add that to the model! For questions of type $t_i$ (ie $t(q)=t_i$), we apply the student&#39;s aptitude from that question type. . $$ begin{aligned} alpha_{s, t} &amp; sim mathrm{Normal}(0,5) gamma_q &amp; sim mathrm{Normal}(0,5) beta_{s, q, t} &amp;= mathrm{logit}^{-1}( alpha_{s,t(q)} - gamma_q) mathrm{correct_{s,q}} &amp; sim mathrm{Bernoulli}( beta_{s,q}) end{aligned}$$More fun (but maybe too much fun for this post :sweat_smile:) is that with multiple question types it would be pretty simple to bake in correlations in student aptitude across question types. . question_types = [1,2,1,2,1,2,1,2,1,2,1,2] @model function irt_2types( correct::Array{Bool}, student::Array{Int64}, question::Array{Int64}, question_type::Array{Int64} ) aptitude_1 = Vector(undef, maximum(student)) aptitude_2 = Vector(undef, maximum(student)) difficulty = Vector(undef, maximum(question)) # priors for i in 1:length(aptitude_1) aptitude_1[i] ~ Normal(0,5) aptitude_2[i] ~ Normal(0,5) end for i in 1:length(difficulty) difficulty[i] ~ Normal(0,5) end β = Vector(undef, length(correct)) for i in 1:length(correct) if question_type[i] == 1 β[i] = aptitude_1[student[i]] - difficulty[question[i]] else β[i] = aptitude_2[student[i]] - difficulty[question[i]] end correct[i] ~ Bernoulli(inv_logit(β[i])) end end; . irt_2types_ch = sample( irt_2types(correct, student, question, question_types), HMC(ϵ, τ), iterations, progress=true, drop_warmup=true) . . Sampling: 100%|█████████████████████████████████████████| Time: 0:00:00 . Chains MCMC chain (1000×20×1 Array{Float64,3}): Iterations = 1:1000 Thinning interval = 1 Chains = 1 Samples per chain = 1000 parameters = aptitude_1[1], aptitude_1[2], aptitude_1[3], aptitude_2[1], aptitude_2[2], aptitude_2[3], difficulty[1], difficulty[2], difficulty[3], difficulty[4], difficulty[5] internals = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, n_steps, nom_step_size, step_size Summary Statistics parameters mean std naive_se mcse ess rhat Symbol Float64 Float64 Float64 Float64 Float64 Float64 aptitude_1[1] 4.1125 2.8127 0.0889 0.7651 12.7687 1.0016 aptitude_1[2] 2.0198 2.9273 0.0926 0.7668 4.0284 1.4551 aptitude_1[3] -4.7104 2.8762 0.0910 0.8053 6.7425 1.0645 aptitude_2[1] 3.2786 3.0173 0.0954 0.7514 5.4254 1.2778 aptitude_2[2] -0.6002 2.5990 0.0822 0.7241 5.6558 1.1660 aptitude_2[3] 1.9599 3.2568 0.1030 0.8387 10.0610 1.1281 difficulty[1] -2.7944 3.3292 0.1053 0.8177 14.5871 1.0535 difficulty[2] -3.8994 3.5653 0.1127 1.0350 2.7201 1.9978 difficulty[3] 0.7524 2.8349 0.0896 0.8140 8.2372 1.0174 difficulty[4] 9.5894 3.2614 0.1031 0.8923 3.0798 1.6956 difficulty[5] -2.1624 3.0569 0.0967 0.8869 5.3197 1.1394 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% Symbol Float64 Float64 Float64 Float64 Float64 aptitude_1[1] -0.7504 2.0848 4.1293 5.5508 10.6943 aptitude_1[2] -3.0840 -0.3602 1.8441 4.4293 7.2316 aptitude_1[3] -9.6865 -6.8462 -5.0387 -2.2494 0.4745 aptitude_2[1] -1.0901 0.8448 2.8353 5.0615 9.8895 aptitude_2[2] -5.0098 -2.5673 -1.0476 1.4656 4.3434 aptitude_2[3] -3.6354 -0.6446 1.8742 4.6117 7.8919 difficulty[1] -8.3563 -5.2372 -3.3224 -0.2932 3.9075 difficulty[2] -10.8610 -6.4562 -3.6604 -0.9632 2.1568 difficulty[3] -4.5461 -1.2926 0.4437 2.8840 6.4110 difficulty[4] 3.5535 7.4417 9.4532 11.5941 16.2606 difficulty[5] -6.8662 -4.6146 -2.6714 0.1172 3.9333 . Test-taker Fatigue . Imagine the test is several hours long. The test taker is pretty likely to perform differently (let&#39;s assume worse) by the end of the test, and that fatigue factor is probably pretty specific to the person. Thus, for the $i^{th}$ question we introduce a linear penalty as a first stab at the idea: . $$ begin{aligned} alpha_s &amp; sim mathrm{Normal}(0,5) phi_s &amp; sim mathrm{LogNormal}(0,1) gamma_q &amp; sim mathrm{Normal}(0,5) beta_{s, q, i} &amp;= mathrm{logit}^{-1}( alpha_s - gamma_q - i phi_s) mathrm{correct_{s,q,i}} &amp; sim mathrm{Bernoulli}( beta_{s,q,i}) end{aligned}$$ question_seq = [1,2,3,4, 1,2,3,4, 1,2,3,4] @model function irt_fatigue( correct::Array{Bool}, student::Array{Int64}, question::Array{Int64}, question_seq::Array{Int64} ) aptitude = Vector(undef, maximum(student)) wimpiness = Vector(undef, maximum(student)) difficulty = Vector(undef, maximum(question)) # priors for i in 1:length(aptitude) aptitude[i] ~ Normal(0,5) wimpiness[i] ~ LogNormal(0,2) end for i in 1:length(difficulty) difficulty[i] ~ Normal(0,5) end β = Vector(undef, length(correct)) for i in 1:length(correct) β[i] = aptitude[student[i]] - difficulty[question[i]] - wimpiness[student[i]] * i * question_seq[i] correct[i] ~ Bernoulli(inv_logit(β[i])) end end; . irt_fatigue_ch = sample( irt_fatigue(correct, student, question, question_seq), HMC(ϵ, τ), iterations, progress=true, drop_warmup=true) . . Sampling: 100%|█████████████████████████████████████████| Time: 0:00:00 . Chains MCMC chain (1000×20×1 Array{Float64,3}): Iterations = 1:1000 Thinning interval = 1 Chains = 1 Samples per chain = 1000 parameters = aptitude[1], aptitude[2], aptitude[3], difficulty[1], difficulty[2], difficulty[3], difficulty[4], difficulty[5], wimpiness[1], wimpiness[2], wimpiness[3] internals = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, n_steps, nom_step_size, step_size Summary Statistics parameters mean std naive_se mcse ess rhat Symbol Float64 Float64 Float64 Float64 Float64 Float64 aptitude[1] 5.5689 3.2672 0.1033 0.9661 5.5541 1.0900 aptitude[2] -0.6428 2.2023 0.0696 0.5558 5.5129 1.2839 aptitude[3] -2.0090 2.7835 0.0880 0.7741 6.2247 1.1309 difficulty[1] -7.5951 3.1442 0.0994 0.8897 10.2621 1.0804 difficulty[2] -3.5479 3.0344 0.0960 0.8538 2.8263 1.9409 difficulty[3] 0.3819 2.0660 0.0653 0.4835 15.8760 1.0060 difficulty[4] 5.3452 3.8158 0.1207 1.0966 6.8170 1.1893 difficulty[5] -3.1397 2.0446 0.0647 0.5193 7.1755 1.2067 wimpiness[1] 0.3146 0.2430 0.0077 0.0457 22.9879 0.9995 wimpiness[2] 0.0530 0.0488 0.0015 0.0073 44.2052 1.0160 wimpiness[3] 0.0864 0.0808 0.0026 0.0220 4.2962 1.2917 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% Symbol Float64 Float64 Float64 Float64 Float64 aptitude[1] -0.0760 2.7155 5.5546 8.5856 10.8985 aptitude[2] -4.8763 -2.0208 -0.7854 0.5966 4.2086 aptitude[3] -6.2673 -4.0574 -2.2741 -0.5126 4.9629 difficulty[1] -13.9438 -9.4788 -7.9346 -5.4993 -0.8206 difficulty[2] -8.2400 -5.8861 -3.8871 -1.4654 2.6733 difficulty[3] -3.2067 -1.1498 0.2113 1.9139 4.7973 difficulty[4] -1.0724 2.2905 5.4179 8.2336 12.3365 difficulty[5] -6.8396 -4.4525 -3.1455 -1.9591 1.3959 wimpiness[1] 0.0278 0.1198 0.2535 0.4515 0.9220 wimpiness[2] 0.0016 0.0162 0.0393 0.0767 0.1814 wimpiness[3] 0.0028 0.0211 0.0614 0.1266 0.2839 . Note on the model specifications . You might be wondering &quot;where did these prior values come from?&quot; or &quot;how did Brad choose these distributions? Why Normal instead of, I dunno, t?&quot;. Good questions! The answer is I didn&#39;t think too hard and just wrote down the first thing that seemed reasonable :sweat_smile: either in terms of the values ($ mathrm{logit}^{-1}(5)$ is a very high - 99-ish% - but not insurmountable level of confidence) or theoretical properties (basically, choose a simple distribution with the right domain and range). . Perhaps you&#39;re also wondering &quot;what&#39;s up with the random mixing in of Greek letters?&quot; You got me there. . Comparison to Collaborative Filtering . Item Response may seem very similar to collaborative filtering, so it&#39;s worth highlighting the differences. . Collaborative filtering aims to complete a sparsely determined preferences/ratings matrix of consumer - item scores (e.g. &quot;User 513 gave product 149 3.5 :star:s&quot;) $M$. A common approach is alternating least squares which iteratively factors the matrix into a product-feature matrix $P$ and a customer-preference matrix $C$. The goal is to create these so that their product &quot;accurately completes&quot; $M$, ie if $CP = overline{M}$ then the difference $M - overline{M}$ is small wherever we have entries for $M$ (remember, $M$ is incomplete). . A key fact is that the matrix $ overline{M}$ (the list of recommendations) is the important output here, and the factors $C$ and $P$ are intriguing but not critical. This is different from Item Response where the background variables describing difficulty and aptitude for each question, student are the primary desired outputs (but we could infer $P( mathrm{correct} | mathrm{student _id}, mathrm{question _id})$ for unseen pairings!). . The other distinction worth mentioning is that the IR models have enormous flexibility in how they inform the probability of success, as we&#39;ve seen above. Collaborative filtering, at least with ALS, is just optimizing a matrix factorization task. Since $ overline{M} = CP$, the user-product score can only be the dot product of the product-feature vector and the customer-preference vector, it attempts to encode &quot;how well do the consumer preferences overlap with the product features.&quot; It does not lend itself to any extensions to capture more domain-specific nuance as we did here. .",
            "url": "http://www.bwg.is/julia/turing/itemresponse/2021/01/05/Item-Response-Models.html",
            "relUrl": "/julia/turing/itemresponse/2021/01/05/Item-Response-Models.html",
            "date": " • Jan 5, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Some Simple Models on Binary Data",
            "content": "To get myself comfortable with Julia and Turing.jl, I wrote out a bunch of toy models on the simplest of datasets: a vector of binary outcomes. To keep myself honest and to have something to refer to, I&#39;m reproducing them here. . using Turing using Bijectors using Gadfly using DataFrames, DataFramesMeta Gadfly.set_default_plot_size(900px, 300px) . . Standard Biased Coin Estimation . Coinflipping is a time-honored introductory example for probability, and for good reason. Readily interpretable, amenable to both analytical solutions and manual calculation. Nevermind that &quot;unfair&quot; coins are essentially impossible to make... . We&#39;ll build two models that are essentially the same but have distinct computational profiles. Bernoulli: . $$ begin{aligned} beta &amp; sim mathrm{Beta}(1,1) y_i &amp; sim mathrm{Bernoulli}( beta) end{aligned}$$And Binomial: . $$ begin{aligned} beta &amp; sim mathrm{Beta}(1,1) mathrm{sum}(y) &amp; sim mathrm{Binomial}( mathrm{length}(y), beta) end{aligned}$$ Bernoulli Model . First thing to do is to translate the Bernoulli code above into a @model in Turing (docs): . @model function coinflip_bernoulli(y) # prior on p p ~ Beta(1, 1) # updates on p for i in 1:length(y) y[i] ~ Bernoulli(p) end end; . It looks more or less like the description above, with the loop for i in 1:length(y) serving the same purpose as the subscript of $y_i$. . data = [1,1,1,0,0,1,0,0,1,1,1,1,1,0,0,0,0,0,1,0,0,1,0,0] &quot;There are $(sum(data)) positive results out of $(length(data)) samples, for a positive rate of $(sum(data) / length(data)).&quot; . &#34;There are 11 positive results out of 24 samples, for a positive rate of 0.4583333333333333.&#34; . So let&#39;s see what the model produces (I&#39;ll also highlight the analytical solution for the mean at 0.458). . iterations = 1000 ϵ = 0.05 τ = 10; chain_bernoulli = sample( coinflip_bernoulli(data), HMC(ϵ, τ), iterations, progress=false, drop_warmup=true); plot(DataFrame(chain_bernoulli), x=:p, xintercept=[0.458], Theme(alphas=[0.6]), Stat.density(bandwidth=0.02), Geom.polygon(fill=true, preserve_order=true), Geom.vline, Coord.cartesian(xmin=0.0, xmax=1.0, ymin=0.0), Guide.yticks(label = false) ) . p -1.5 -1.0 -0.5 0.0 0.5 1.0 1.5 2.0 2.5 -1.00 -0.95 -0.90 -0.85 -0.80 -0.75 -0.70 -0.65 -0.60 -0.55 -0.50 -0.45 -0.40 -0.35 -0.30 -0.25 -0.20 -0.15 -0.10 -0.05 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 1.05 1.10 1.15 1.20 1.25 1.30 1.35 1.40 1.45 1.50 1.55 1.60 1.65 1.70 1.75 1.80 1.85 1.90 1.95 2.00 -1 0 1 2 -1.0 -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.0 h,j,k,l,arrows,drag to pan i,o,+,-,scroll,shift-drag to zoom r,dbl-click to reset c for coordinates ? for help ? Binomial Model . Now let&#39;s take a look at the equivalent model using a Binomial distribution that expresses the exact same underlying phenomena. In Turing: . @model function coinflip_binomial(heads::Int64, flips::Int64) # prior on p p ~ Beta(1, 1) # update on p heads ~ Binomial(flips, p) end; . heads = sum(data) flips = length(data) chain_binomial = sample( coinflip_binomial(heads, flips), HMC(ϵ, τ), iterations, progress=false, drop_warmup=true); plot(DataFrame(chain_binomial), x=:p, xintercept=[0.458], Theme(alphas=[0.6]), Stat.density(bandwidth=0.02), Geom.polygon(fill=true, preserve_order=true), Geom.vline, Coord.cartesian(xmin=0.0, xmax=1.0, ymin=0.0), Guide.yticks(label = false) ) . . p -1.5 -1.0 -0.5 0.0 0.5 1.0 1.5 2.0 2.5 -1.00 -0.95 -0.90 -0.85 -0.80 -0.75 -0.70 -0.65 -0.60 -0.55 -0.50 -0.45 -0.40 -0.35 -0.30 -0.25 -0.20 -0.15 -0.10 -0.05 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 1.05 1.10 1.15 1.20 1.25 1.30 1.35 1.40 1.45 1.50 1.55 1.60 1.65 1.70 1.75 1.80 1.85 1.90 1.95 2.00 -1 0 1 2 -1.0 -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.0 h,j,k,l,arrows,drag to pan i,o,+,-,scroll,shift-drag to zoom r,dbl-click to reset c for coordinates ? for help ? Other Parameter Spaces . Going further afield, we can also model $ beta$ on an unconstrained scale ($ mathbb{R}$ instead of the unit interval $[0,1]$) by linking the domains with $ mathrm{logit}^{-1}$: . $$ begin{aligned} mathrm{logit}^{-1}&amp;: mathbb{R} to (0, 1) mathrm{logit}^{-1}(x) &amp;= frac{e^x}{e^x + 1} end{aligned}$$Under this transformation, we don&#39;t have to worry about ensuring our parameters stay in the range of $(0,1)$ - check out $ rho$ here: . $$ begin{aligned} rho &amp; sim mathrm{Normal}(0, 5) beta &amp;= mathrm{logit}^{-1}( rho) y_i &amp; sim mathrm{Bernoulli}( beta) end{aligned}$$On it&#39;s own, this seems like a frivolous transformation but it allows us to incorporate multiple signals into our determination of the probability of a positive result. Turns out, this is just logistic regression. Imagine we have one outcome $y$ that depends on several inputs $x_1, x_2, ldots, x_n$: . $$ begin{aligned} rho_i &amp; sim mathrm{Normal}(0,5) beta &amp;= mathrm{logit}^{-1}( rho_1 x_1 + rho_2 x_2 + ldots + rho_n x_n) y_i &amp; sim mathrm{Bernoulli}( beta) end{aligned}$$Because we pass the regression product through $ mathrm{logit}^{-1}$, we know the value of $ beta$ will be between 0 and 1. If we didn&#39;t apply this transformation then adding up the components of $ beta$ could lead to values outside of that range, (and therefore not in the support of the Bernoulli distribution) which would cause the computation to fail. . The same approach works for the Binomial model: . $$ begin{aligned} rho_i &amp; sim mathrm{Normal}(0,5) beta &amp;= mathrm{logit}^{-1}( rho_1 x_1 + rho_2 x_2 + ldots + rho_n x_n) mathrm{sum}(y) &amp; sim mathrm{Binomial}( mathrm{length}(y), beta) end{aligned}$$ Logit calculations . Turing allows us to create a logit function in two ways. One is in pure Julia code (note I didn&#39;t apply a type assertion to the x argument: things can get messy here with automatic differentiation): . function invlogit(x) ex = exp(x) return ex / (1 + ex) end; . It&#39;s also possible to use the same transformations that Turing uses internally from the Bijectors.jl library. Some sampling algorithms like HMC require an unbounded sampling space to (at least up to Float64 constraints...). To support that on bounded domains, the Bijectors library creates functions that map (smoothly) between continuous spaces (Bijectors README). . logit = bijector(Beta()) # bijection: (0, 1) → ℝ inv_logit = inv(logit) # bijection: ℝ → (0, 1) @model function coinflip_invlogit(heads::Int64, flips::Int64) # prior on p logit_p ~ Normal(0, 5) # or any unbounded distribution # update on p heads ~ Binomial(flips, invlogit(logit_p)) end; . &quot;Our favorite value: $(logit(0.458)).&quot; . &#34;Our favorite value: -0.16839681732546127.&#34; . long_heads = sum(data) long_flips = length(data) chain_invlogit = sample( coinflip_invlogit(long_heads, long_flips), HMC(ϵ, τ), iterations, progress=false, drop_warmup=true); plot(DataFrame(chain_invlogit), x=:logit_p, xintercept=[-0.168], Theme(alphas=[0.6]), Stat.density(bandwidth=0.05), Geom.polygon(fill=true, preserve_order=true), Geom.vline, Coord.cartesian(ymin=0.0), Guide.yticks(label = false) ) . . logit_p -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 -6.0 -5.8 -5.6 -5.4 -5.2 -5.0 -4.8 -4.6 -4.4 -4.2 -4.0 -3.8 -3.6 -3.4 -3.2 -3.0 -2.8 -2.6 -2.4 -2.2 -2.0 -1.8 -1.6 -1.4 -1.2 -1.0 -0.8 -0.6 -0.4 -0.2 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 2.2 2.4 2.6 2.8 3.0 3.2 3.4 3.6 3.8 4.0 4.2 4.4 4.6 4.8 5.0 5.2 5.4 5.6 5.8 6.0 -6 -3 0 3 6 -6.0 -5.5 -5.0 -4.5 -4.0 -3.5 -3.0 -2.5 -2.0 -1.5 -1.0 -0.5 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0 h,j,k,l,arrows,drag to pan i,o,+,-,scroll,shift-drag to zoom r,dbl-click to reset c for coordinates ? for help ? Note the new x-axis which is the transformation of the previous axis. Here are some helpful values: . $$ begin{aligned} mathrm{logit}^{-1}(1.0) &amp;= 0.73 mathrm{logit}^{-1}(0) &amp;= frac{1}{2} mathrm{logit}^{-1}(-0.168) &amp;= 0.458 mathrm{logit}^{-1}(-1.0) &amp;= 0.27 end{aligned}$$ Performance Difference . Despite describing essentially the same model, performance will differ significantly beteen the Binomial and the Bernoulli cases especially as the volume of data increases. The log-likelihood calculations in each sample loop are $O(1)$ versus $O( mathrm{rows})$, respectively. Here&#39;s a comparison with a modestly larger dataset: . long_data = repeat(data, 10); @time sample( coinflip(long_data), HMC(ϵ, τ), iterations, progress=false); . UndefVarError: coinflip not defined Stacktrace: [1] top-level scope at ./timing.jl:174 [inlined] [2] top-level scope at ./In[12]:0 [3] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091 . heads = sum(long_data) flips = length(long_data) @time sample( coinflip_binomial(heads, flips), HMC(ϵ, τ), iterations, progress=false); . 1.246062 seconds (2.06 M allocations: 114.837 MiB, 3.87% gc time) . Caution! . Just a little &quot;gotcha&quot; I ran into. The following model won&#39;t work, due to design choices in Turing: . @model function coinflip_BROKEN_THIS_WONT_WORK_AAAAAGH(y::Array{Int64}) # prior on p p ~ Beta(1, 1) # updates on p # these lines are the problem. heads = sum(y) # heads is not RV or argument heads ~ Binomial(length(y), p) # so it can&#39;t be on LHS of ~ end; . The reason is that Turing assumes that all variables on the left hand side of ~ are either . random variables (generated by Turing) or | declared as inputs to the function | By way of analogy to Stan, the @model block of Turing is only intended to represent the parameter, tranformed parameter and model blocks of Stan. As Turing is just Julia code, this is little inconvenience (just do the data transformations in Julia first, it&#39;s more efficient anyway!) but it can be a bit of a surprise and the error message is difficult to interpret. . Incorporating Prior Knowledge . The above models depend on unexplained constants in the Beta distribution ($ mathrm{Beta}(1,1)$ vs, say, $ mathrm{Beta}(13.859, pi^e)$). Those choices were left unjustified and unexplained and here we&#39;ll put some more thought into them. . Let&#39;s assume you are passingly familiar with the concept of flipping coins. Consequently you reasonably expect nearly every coin to be fair and nearly every person you know to not be Persi Diaconis. Personally, I&#39;d need to see a lot of data to accept that a coin had a substantial bias, so in this section we explore how to bake that belief intentionally into our model as a prior distribution (the parameters of Beta, in this case). This is a small change to the model but we&#39;ll explore the impacts of a few alternatives: . $$ begin{aligned} beta &amp; sim mathrm{Beta}(1,1) &amp; mathrm{ versus} beta &amp; sim mathrm{Beta}(5,5) &amp; mathrm{ versus} beta &amp; sim mathrm{Beta}(50,50) &amp; mathrm{ versus} beta &amp; sim mathrm{Beta}(15,5)&amp; mathrm{ (for fun)} beta &amp; sim mathrm{Beta}(0.5,0.5)&amp; mathrm{ (for more fun)} end{aligned}$$ In this particular case, the $ mathrm{Beta}$ distribution is what&#39;s known as a conjugate prior for both the Bernoulli and Binomial distributions. That means we can interpret the prior as essentially just bringing more data to do table. For example, we can think of $ mathrm{Beta}(5,5)$ as showing up and pretending we&#39;d already observed $4 = 5-1$ heads and $4=5-1$ tails ahead of time. Similarly, $ mathrm{Beta}(15,5)$ is like baking in knowledge about $14 = 15-1$ heads and $4=5-1$ tails outside of the observed data. The &quot;subtract 1&quot; business is just part of the $ mathrm{Beta}$ distribution details. . x = .001:0.001:.999 Θ = [(1,1), (5,5), (50,50), (15,5), (0.5,0.5)] distributions = [ DataFrame( x=x, ymax=pdf.(Beta(θ[1], θ[2]), x), ymin=0.0, θ=&quot;$θ&quot;) for θ in Θ] plot(vcat(distributions...), x=:x, y=:ymax, ymin=:ymin, ymax=:ymax, color=:θ, Geom.line, Geom.ribbon, Theme(alphas=[0.6]), Guide.ylabel(nothing), Guide.yticks(label=false), Guide.title(&quot;Prior Distributions&quot;), Coord.cartesian(xmin=0.0, xmax=1.0, ymin=0.0) ) . x -1.5 -1.0 -0.5 0.0 0.5 1.0 1.5 2.0 2.5 -1.00 -0.95 -0.90 -0.85 -0.80 -0.75 -0.70 -0.65 -0.60 -0.55 -0.50 -0.45 -0.40 -0.35 -0.30 -0.25 -0.20 -0.15 -0.10 -0.05 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 1.05 1.10 1.15 1.20 1.25 1.30 1.35 1.40 1.45 1.50 1.55 1.60 1.65 1.70 1.75 1.80 1.85 1.90 1.95 2.00 -1 0 1 2 -1.0 -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.0 (1, 1) (5, 5) (50, 50) (15, 5) (0.5, 0.5) θ h,j,k,l,arrows,drag to pan i,o,+,-,scroll,shift-drag to zoom r,dbl-click to reset c for coordinates ? for help ? Prior Distributions @model function coinflip_binomial_prior(heads::Int64, flips::Int64, a, b) # prior on p p ~ Beta(a, b) # update on p heads ~ Binomial(flips, p) end; . Rerunning the same data against each of the prior distributions yields the following new posterior distributions (remember $ mathrm{Beta}(1,1)$ was the original prior). . function tag_column(df, tag) df[!,:θ] .= tag return df end; iterations = 2000 chain_binomial_by_priors = [tag_column(DataFrame(sample( coinflip_binomial_prior(heads, flips, θ[1], θ[2]), HMC(ϵ, τ), iterations, progress=false, drop_warmup=true)), &quot;$θ&quot;) for θ in Θ]; plot(vcat(chain_binomial_by_priors...), x=:p, xintercept=[0.458], color=:θ,Theme(alphas=[0.4]), Geom.density, Geom.vline, Guide.title(&quot;Sampled Posterior Distributions&quot;), Coord.cartesian(xmin=0.0, xmax=1.0, ymin=0.0), Guide.yticks(label = false) ) . . p -1.5 -1.0 -0.5 0.0 0.5 1.0 1.5 2.0 2.5 -1.00 -0.95 -0.90 -0.85 -0.80 -0.75 -0.70 -0.65 -0.60 -0.55 -0.50 -0.45 -0.40 -0.35 -0.30 -0.25 -0.20 -0.15 -0.10 -0.05 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 1.05 1.10 1.15 1.20 1.25 1.30 1.35 1.40 1.45 1.50 1.55 1.60 1.65 1.70 1.75 1.80 1.85 1.90 1.95 2.00 -1 0 1 2 -1.0 -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.0 (1, 1) (5, 5) (50, 50) (15, 5) (0.5, 0.5) θ h,j,k,l,arrows,drag to pan i,o,+,-,scroll,shift-drag to zoom r,dbl-click to reset c for coordinates ? for help ? Sampled Posterior Distributions The posterior samples are compromises between the observed data and the prior distributions. To reinforce the previous point about conjugate priors, here are the analytically deduced posterior distributions: . post_distributions = [ DataFrame( x=x, ymax=pdf.(Beta(θ[1] + 11, θ[2] + 13), x), ymin=0.0, θ=&quot;$θ&quot;) for θ in Θ] plot(vcat(post_distributions...), x=:x, y=:ymax, ymin=:ymin, ymax=:ymax, color=:θ, Geom.line, Geom.ribbon, Theme(alphas=[0.6]), Guide.ylabel(nothing), Guide.yticks(label=false), Guide.title(&quot;Analytical Posterior Distributions&quot;), Coord.cartesian(xmin=0.0, xmax=1.0, ymin=0.0) ) . . x -1.5 -1.0 -0.5 0.0 0.5 1.0 1.5 2.0 2.5 -1.00 -0.95 -0.90 -0.85 -0.80 -0.75 -0.70 -0.65 -0.60 -0.55 -0.50 -0.45 -0.40 -0.35 -0.30 -0.25 -0.20 -0.15 -0.10 -0.05 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 1.05 1.10 1.15 1.20 1.25 1.30 1.35 1.40 1.45 1.50 1.55 1.60 1.65 1.70 1.75 1.80 1.85 1.90 1.95 2.00 -1 0 1 2 -1.0 -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.0 (1, 1) (5, 5) (50, 50) (15, 5) (0.5, 0.5) θ h,j,k,l,arrows,drag to pan i,o,+,-,scroll,shift-drag to zoom r,dbl-click to reset c for coordinates ? for help ? Analytical Posterior Distributions You can see how it lines up with the samples from the posterior via HMC. The fun of something like Turing is that you don&#39;t always have access to simple conjugate priors for your distribution, but you can still do all the same fancy stuff even without pure analytical solutions! . Bias - Variance Tradeoff . Looking at these plots, this is a great example of the bias-variance tradeoff: . bias: model rigidity can introduce error by failing to fit the underlying phenomena correctly | variance: model flexibility can introduce generalization error from random data fluctuations | . Above, the green model is totally misspecified and somewhat rigid (relative to the size of the data), while the low-numbered priors are all too flexible given our domain knowledge. .",
            "url": "http://www.bwg.is/julia/turing/binary/2020/12/30/Turing-Examples-1.html",
            "relUrl": "/julia/turing/binary/2020/12/30/Turing-Examples-1.html",
            "date": " • Dec 30, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I’m Brad, a data scientist with experience building awesome teams. . This is me, and this too! . .",
          "url": "http://www.bwg.is/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "http://www.bwg.is/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}