{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer LTV\n",
    "- categories: [Julia, Turing, Churn, Survival, LTV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "using Turing\n",
    "using Gadfly\n",
    "using DataFrames, DataFramesMeta\n",
    "Gadfly.set_default_plot_size(900px, 300px)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customer Lifetime Value (LTV or CLTV) is the total dollar value a consumer will spend at a business throughout their life. The concept is as important as the definition is straightforward - businesses very often want to know which consumers are their whales and which are eating up their marketing or infrastructure budgets with little or no value returned. This is pretty tricky and there are a few approaches you can take:\n",
    "\n",
    "### Observational\n",
    "\n",
    "**Naive calculation**. The following will give you an average that is delightfully simple but tragically wrong:\n",
    "\n",
    "$$\\mathrm{LTV} = \\frac{1}{|\\mathrm{Customers}|}\\sum_{\\mathrm{orders}} \\mathrm{Order\\ Value}$$\n",
    "\n",
    "Assuming (hmm) that LTV is constant over time, this will converge to the true average LTV value as customers churn (and thus achieve their final lifetime value). New customers will continue to weigh the average down and make it an underestimate. There are some of these sort of equations floating around the tubes.\n",
    "\n",
    "**Wait and see**. Simialr algorithm to the above, the major difference is applying this to only a small cohort from a brief window in time. Just follow along with that group and add up how much they spend. This is simple and will get to the true LTV of that cohort faster but it's still typically too slow to be useful. By the time you know, it's months/quarters/years later (depending on the churn characteristics of your product) and most insights you might glean are no longer relevant to your product roadmap.\n",
    "\n",
    "### Modeled\n",
    "\n",
    "**Machine Learning** :tada:. There are a bunch of ML approaches here that can be found relatively easily online (but apparently not easy enough for me to find them again to include here). IIRC, one was using a random forest (or GBM, or whatever) to predict \n",
    "\n",
    "$$P(\\mathrm{purchase\\ in\\ next\\ period}|\\mathcal{D})$$ \n",
    "\n",
    "and then in a second stage model (conditioned on the purchase outcome) predict the order value of said purchase.\n",
    "\n",
    "It's a reasonably standard approach: decompose the problem into churn, expected future purchases, and expected value per purchase. There are a bunch of approaches that are tailored to this decomposition by breaking down the inputs into the so called **RFM** metrics: \n",
    "\n",
    "- **R**ecency: time since the last purchase,\n",
    "- **F**requency: number of purchases per time period, \n",
    "- **M**onetary value: average order value.\n",
    "\n",
    "Note that we'll use days for the time scale.\n",
    "\n",
    "**Buy 'til You Die**. https://www.zdnet.com/article/nikes-purchase-of-analytics-firm-zodiac-highlights-focus-on-customer-lifetime-value/\n",
    "http://www.brucehardie.com/papers/bgnbd_2004-04-20.pdf\n",
    "\n",
    "\n",
    "**Custom Model**. That's what we're going to do! Fader and Hardie do a great job of making their work look harder than necessary so I can't be bothered to decode it (and anyway, [Alex did a great job](https://medium.com/ordergroove-engineering/every-customer-counts-52aa70e4f85)). That said, I'm going to take what I believe to be a similar approach:\n",
    "\n",
    "1. Estimate churn based on **R**ecency and **F**requency.\n",
    "2. Set up a super simple survival model to understand the expected number of future purchases using sample from (1) as the churn signal.\n",
    "3. Scale by **M**onetary value.\n",
    "\n",
    "By building these out independently we can understood the whole model but first figuring it out component-by-component. It also provides a quick way to make single-component adjustments that might be important. For instance, some retailers have an extremely wide spread of possible order values (e.g. Walmart, you can buy a stick of gum or probably a boat or something). If there are orders-of-magnitude differences in purchase value then you better model that out so you know exactly which consumers are likely to find themselves that lucrative long tail. In my experience, lognormal is a decent start but the tail is still too light."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Models\n",
    "\n",
    "### Active from RF\n",
    "\n",
    "We sample when we expect the customer's next purchase to occur based on what we've observed of their frequency, then we compare that to how long it's been since they purchased. If we expected them to purchase already, we count them as churned. Note that we don't have any kind of regularization and just assume F is a fine number for us. Exercise for the reader to make that more stable :smile:.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathrm{next\\ purchase} &\\sim \\mathrm{Exponential}(F) \\\\\n",
    "\\mathrm{active} &= R < \\mathrm{next\\ purchase}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### Future Purchases from RF+Active\n",
    "\n",
    "We'd like to then take the inferences above and use them to understand churn as a function of time, or perhaps number of orders. In other words:\n",
    "\n",
    "$$P(\\mathrm{churned}_{t=i} | \\mathrm{active}_{t=i-1})$$\n",
    "\n",
    "Here we find some wrinkles. Most notably, what to do with consumers that have recently purchased and we don't know if they are going to churn before the next purchase? This is called censoring, which comes in many directional varieties and this variety is called right-censoring (on the \"right\" side of our time interval, we don't yet have data on the outcome). We'll ignore that for now, and instead assume \"constant hazard\" on the data we can observe, ie the rate at which users remain active ($\\rho$) is constant across all time points.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\rho &\\sim \\mathrm{Beta}(1,1)\\\\\n",
    "\\mathrm{purchases}_{uncensored} &\\sim \\mathrm{Geometric(\\rho)}\\\\\n",
    "(\\mathrm{Future\\ purchases}) &\\sim \n",
    "    \\begin{cases}\n",
    "    \\mathrm{Geometric}(\\rho) & \\mathrm{if\\ active} \\\\\n",
    "    \\mathrm{Dirac}(0) & \\mathrm{otherwise}\n",
    "    \\end{cases}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### LTV from M+Future Purchases\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathrm{Future\\ value} &= \\mathrm{Future\\ purchases} * \\mathrm{AOV}\\\\\n",
    "\\mathrm{Lifetime\\ value} &= \\mathrm{Future\\ value} + \\mathrm{Past\\ value}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimator of the survival function $S(t)$ (the probability that life is longer than $t$) is given by:\n",
    "\n",
    "$$\\widehat {S}(t)=\\prod \\limits _{i:\\ t_{i}\\leq t}\\left(1-{\\frac {d_{i}}{n_{i}}}\\right)$$\n",
    "\n",
    "with $t_{i}$ a time when at least one event happened, $d_i$ the number of events (e.g., deaths) that happened at time $t_{i}$, and $n_{i}$ the individuals **known to have survived** (have not yet had an event or been censored) up to time $t_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[order_count, churned_at_order_count, known_active_at_order_count]\n",
    "\n",
    "definition of churned_at_order_count = next_purchase < R (ie active field)\n",
    "\n",
    "definition of known_active_at_order_count = made at least this many orders\n",
    "\n",
    "then want to see:\n",
    "[order_count, 1 - (churned_at_order_count / lag(known_active_at_order_count)) = S(t) factor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding it with Turing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "active (generic function with 1 method)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@model function active(custs::Array{CustomerData})\n",
    "    predicted_purchase_days = Vector(undef, length(custs))\n",
    "    active = Vector{Bool}(undef, length(custs))\n",
    "\n",
    "    for i in 1:length(custs)\n",
    "        predicted_purchase_days[i] ~ Exponential(custs[i].frequency) \n",
    "        active[i] = predicted_purchase_days[i] > custs[i].recency\n",
    "    end\n",
    "    \n",
    "    return active\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_data = [\n",
    "    CustomerData(2, 10.0, 123),\n",
    "    CustomerData(10, 10, 123),\n",
    "    CustomerData(23, 10, 123),\n",
    "    CustomerData(2, 2, 123),\n",
    "    CustomerData(10, 2, 123),\n",
    "    CustomerData(23, 2, 123),\n",
    "];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chains MCMC chain (2000×15×1 Array{Float64,3}):\n",
       "\n",
       "Iterations        = 1:2000\n",
       "Thinning interval = 1\n",
       "Chains            = 1\n",
       "Samples per chain = 2000\n",
       "parameters        = predicted_purchase_days[1], predicted_purchase_days[2], predicted_purchase_days[3], predicted_purchase_days[4], predicted_purchase_days[5], predicted_purchase_days[6]\n",
       "internals         = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, n_steps, nom_step_size, step_size\n",
       "\n",
       "Summary Statistics\n",
       " \u001b[1m                 parameters \u001b[0m \u001b[1m    mean \u001b[0m \u001b[1m     std \u001b[0m \u001b[1m naive_se \u001b[0m \u001b[1m    mcse \u001b[0m \u001b[1m      e\u001b[0m ⋯\n",
       " \u001b[90m                     Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m  Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m  Float\u001b[0m ⋯\n",
       "\n",
       "  predicted_purchase_days[1]    9.3736    9.5614     0.2138    0.7994   198.81 ⋯\n",
       "  predicted_purchase_days[2]    9.8823    9.6488     0.2158    0.7492   151.43 ⋯\n",
       "  predicted_purchase_days[3]   10.9717   10.6465     0.2381    0.7395   168.51 ⋯\n",
       "  predicted_purchase_days[4]    1.9534    1.9601     0.0438    0.1553   128.13 ⋯\n",
       "  predicted_purchase_days[5]    1.8112    1.8519     0.0414    0.1353   165.92 ⋯\n",
       "  predicted_purchase_days[6]    2.0249    2.0823     0.0466    0.1817   130.08 ⋯\n",
       "\u001b[31m                                                               2 columns omitted\u001b[0m\n",
       "\n",
       "Quantiles\n",
       " \u001b[1m                 parameters \u001b[0m \u001b[1m    2.5% \u001b[0m \u001b[1m   25.0% \u001b[0m \u001b[1m   50.0% \u001b[0m \u001b[1m   75.0% \u001b[0m \u001b[1m   97.5%\u001b[0m ⋯\n",
       " \u001b[90m                     Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64\u001b[0m ⋯\n",
       "\n",
       "  predicted_purchase_days[1]    0.4989    2.9971    6.5270   12.3057   33.8535 ⋯\n",
       "  predicted_purchase_days[2]    0.3161    2.8526    7.0404   13.6432   35.3383 ⋯\n",
       "  predicted_purchase_days[3]    0.7023    3.7163    7.6839   14.8132   38.9750 ⋯\n",
       "  predicted_purchase_days[4]    0.0332    0.5434    1.4089    2.6586    7.2278 ⋯\n",
       "  predicted_purchase_days[5]    0.0408    0.4467    1.2543    2.5747    6.5168 ⋯\n",
       "  predicted_purchase_days[6]    0.0188    0.5065    1.4062    2.8350    7.4022 ⋯\n"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterations = 2000\n",
    "ϵ = 0.05\n",
    "τ = 10;\n",
    "\n",
    "chain_ltv = sample(\n",
    "    active(cust_data), \n",
    "    HMC(ϵ, τ), iterations, \n",
    "    progress=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>x1</th><th>x2</th><th>x3</th><th>x4</th><th>x5</th><th>x6</th></tr><tr><th></th><th>Bool</th><th>Bool</th><th>Bool</th><th>Bool</th><th>Bool</th><th>Bool</th></tr></thead><tbody><p>2,000 rows × 6 columns</p><tr><th>1</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>2</th><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>3</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>4</th><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>5</th><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>6</th><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>7</th><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>8</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>9</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>10</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>11</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>12</th><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>13</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>14</th><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>15</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>16</th><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><th>17</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>18</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>19</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>20</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>21</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>22</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>23</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>24</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>25</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>26</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>27</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>28</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>29</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>30</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& x1 & x2 & x3 & x4 & x5 & x6\\\\\n",
       "\t\\hline\n",
       "\t& Bool & Bool & Bool & Bool & Bool & Bool\\\\\n",
       "\t\\hline\n",
       "\t1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t2 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t3 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t4 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t5 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t6 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t7 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t8 & 1 & 1 & 0 & 0 & 0 & 0 \\\\\n",
       "\t9 & 1 & 1 & 0 & 0 & 0 & 0 \\\\\n",
       "\t10 & 1 & 1 & 0 & 0 & 0 & 0 \\\\\n",
       "\t11 & 1 & 1 & 0 & 0 & 0 & 0 \\\\\n",
       "\t12 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t13 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
       "\t14 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t15 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t16 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
       "\t17 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t18 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
       "\t19 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t20 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t21 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t22 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
       "\t23 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
       "\t24 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
       "\t25 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
       "\t26 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
       "\t27 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
       "\t28 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
       "\t29 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
       "\t30 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m2000×6 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m x1    \u001b[0m\u001b[1m x2    \u001b[0m\u001b[1m x3    \u001b[0m\u001b[1m x4    \u001b[0m\u001b[1m x5    \u001b[0m\u001b[1m x6    \u001b[0m\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Bool  \u001b[0m\u001b[90m Bool  \u001b[0m\u001b[90m Bool  \u001b[0m\u001b[90m Bool  \u001b[0m\u001b[90m Bool  \u001b[0m\u001b[90m Bool  \u001b[0m\n",
       "──────┼──────────────────────────────────────────\n",
       "    1 │ false  false  false  false  false  false\n",
       "    2 │  true  false  false  false  false  false\n",
       "    3 │ false  false  false  false  false  false\n",
       "    4 │  true  false  false  false  false  false\n",
       "    5 │  true  false  false  false  false  false\n",
       "    6 │  true  false  false  false  false  false\n",
       "    7 │  true  false  false  false  false  false\n",
       "    8 │  true   true  false  false  false  false\n",
       "    9 │  true   true  false  false  false  false\n",
       "   10 │  true   true  false  false  false  false\n",
       "   11 │  true   true  false  false  false  false\n",
       "  ⋮   │   ⋮      ⋮      ⋮      ⋮      ⋮      ⋮\n",
       " 1991 │  true  false  false  false  false  false\n",
       " 1992 │  true  false  false  false  false  false\n",
       " 1993 │  true   true  false  false  false  false\n",
       " 1994 │  true   true  false  false  false  false\n",
       " 1995 │  true   true  false  false  false  false\n",
       " 1996 │  true   true  false  false  false  false\n",
       " 1997 │  true   true  false  false  false  false\n",
       " 1998 │  true   true  false  false  false  false\n",
       " 1999 │  true   true  false  false  false  false\n",
       " 2000 │  true   true  false  false  false  false\n",
       "\u001b[31m                                1979 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(hcat(generated_quantities(active(cust_data), chain_ltv)...)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "plot(DataFrame(chain_ltv), x=:, Theme(alphas=[0.6]),\n",
    "    Stat.density(bandwidth=0.02), Geom.polygon(fill=true, preserve_order=true),\n",
    "    Coord.cartesian(xmin=0.0, xmax=1.0, ymin=0.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for customer in list:\n",
    "    if churned:\n",
    "        d[customer.ordercount] += 1\n",
    "    for i in 1:customer.ordercount:\n",
    "        n[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct CustomerData\n",
    "    recency::Int64\n",
    "    frequency::Float64\n",
    "    money::Float64\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v = Vector{Float64}(undef, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "btyd (generic function with 1 method)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct LtvGQs\n",
    "    active::Vector{Bool}\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chains MCMC chain (2000×15×1 Array{Float64,3}):\n",
       "\n",
       "Iterations        = 1:2000\n",
       "Thinning interval = 1\n",
       "Chains            = 1\n",
       "Samples per chain = 2000\n",
       "parameters        = days_to_next_predicted_purchase[1], days_to_next_predicted_purchase[2], days_to_next_predicted_purchase[3], days_to_next_predicted_purchase[4], days_to_next_predicted_purchase[5], days_to_next_predicted_purchase[6]\n",
       "internals         = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, n_steps, nom_step_size, step_size\n",
       "\n",
       "Summary Statistics\n",
       " \u001b[1m                         parameters \u001b[0m \u001b[1m    mean \u001b[0m \u001b[1m     std \u001b[0m \u001b[1m naive_se \u001b[0m \u001b[1m    mcse \u001b[0m ⋯\n",
       " \u001b[90m                             Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m  Float64 \u001b[0m \u001b[90m Float64 \u001b[0m ⋯\n",
       "\n",
       "  days_to_next_predicted_purchase[1]    9.1810    9.3432     0.2089    0.7770  ⋯\n",
       "  days_to_next_predicted_purchase[2]    9.8585    9.7331     0.2176    0.8114  ⋯\n",
       "  days_to_next_predicted_purchase[3]   10.6240    9.7998     0.2191    0.6761  ⋯\n",
       "  days_to_next_predicted_purchase[4]    1.7863    1.8346     0.0410    0.1468  ⋯\n",
       "  days_to_next_predicted_purchase[5]    1.9792    1.9113     0.0427    0.1309  ⋯\n",
       "  days_to_next_predicted_purchase[6]    1.8254    1.9007     0.0425    0.1877  ⋯\n",
       "\u001b[31m                                                               2 columns omitted\u001b[0m\n",
       "\n",
       "Quantiles\n",
       " \u001b[1m                         parameters \u001b[0m \u001b[1m    2.5% \u001b[0m \u001b[1m   25.0% \u001b[0m \u001b[1m   50.0% \u001b[0m \u001b[1m   75.0% \u001b[0m \u001b[1m\u001b[0m ⋯\n",
       " \u001b[90m                             Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m\u001b[0m ⋯\n",
       "\n",
       "  days_to_next_predicted_purchase[1]    0.1603    2.3690    6.4214   12.8901   ⋯\n",
       "  days_to_next_predicted_purchase[2]    0.2222    2.8749    6.8731   13.9526   ⋯\n",
       "  days_to_next_predicted_purchase[3]    0.5953    3.4112    7.8910   14.9332   ⋯\n",
       "  days_to_next_predicted_purchase[4]    0.0942    0.5068    1.1622    2.4613   ⋯\n",
       "  days_to_next_predicted_purchase[5]    0.0562    0.6334    1.4277    2.7009   ⋯\n",
       "  days_to_next_predicted_purchase[6]    0.0138    0.4309    1.2307    2.5427   ⋯\n",
       "\u001b[31m                                                                1 column omitted\u001b[0m\n"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>x1</th></tr><tr><th></th><th>Tuple…</th></tr></thead><tbody><p>2,000 rows × 1 columns</p><tr><th>1</th><td>([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>2</th><td>([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>3</th><td>([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>4</th><td>([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>5</th><td>([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>6</th><td>([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>7</th><td>([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>8</th><td>([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>9</th><td>([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>10</th><td>([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>11</th><td>([1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>12</th><td>([1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>13</th><td>([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>14</th><td>([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>15</th><td>([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>16</th><td>([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>17</th><td>([1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>18</th><td>([1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>19</th><td>([1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>20</th><td>([1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0])</td></tr><tr><th>21</th><td>([1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0])</td></tr><tr><th>22</th><td>([1, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0])</td></tr><tr><th>23</th><td>([1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0])</td></tr><tr><th>24</th><td>([1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0])</td></tr><tr><th>25</th><td>([1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>26</th><td>([1, 1, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0])</td></tr><tr><th>27</th><td>([1, 1, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0])</td></tr><tr><th>28</th><td>([1, 1, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0])</td></tr><tr><th>29</th><td>([1, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0])</td></tr><tr><th>30</th><td>([1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])</td></tr><tr><th>&vellip;</th><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|c}\n",
       "\t& x1\\\\\n",
       "\t\\hline\n",
       "\t& Tuple…\\\\\n",
       "\t\\hline\n",
       "\t1 & ([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t2 & ([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t3 & ([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t4 & ([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t5 & ([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t6 & ([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t7 & ([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t8 & ([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t9 & ([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t10 & ([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t11 & ([1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t12 & ([1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t13 & ([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t14 & ([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t15 & ([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t16 & ([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t17 & ([1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t18 & ([1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t19 & ([1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t20 & ([1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]) \\\\\n",
       "\t21 & ([1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]) \\\\\n",
       "\t22 & ([1, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]) \\\\\n",
       "\t23 & ([1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]) \\\\\n",
       "\t24 & ([1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]) \\\\\n",
       "\t25 & ([1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t26 & ([1, 1, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0]) \\\\\n",
       "\t27 & ([1, 1, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0]) \\\\\n",
       "\t28 & ([1, 1, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0]) \\\\\n",
       "\t29 & ([1, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]) \\\\\n",
       "\t30 & ([1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]) \\\\\n",
       "\t$\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m2000×1 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m x1                                \u001b[0m\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Tuple…                            \u001b[0m\n",
       "──────┼───────────────────────────────────\n",
       "    1 │ (Bool[0, 0, 0, 0, 0, 0], Bool[0,…\n",
       "    2 │ (Bool[0, 0, 0, 0, 0, 0], Bool[0,…\n",
       "    3 │ (Bool[0, 0, 0, 0, 0, 0], Bool[0,…\n",
       "    4 │ (Bool[0, 0, 0, 0, 0, 0], Bool[0,…\n",
       "    5 │ (Bool[0, 0, 0, 0, 0, 0], Bool[0,…\n",
       "    6 │ (Bool[0, 0, 0, 0, 0, 0], Bool[0,…\n",
       "    7 │ (Bool[0, 0, 0, 0, 0, 0], Bool[0,…\n",
       "    8 │ (Bool[0, 0, 0, 0, 0, 0], Bool[0,…\n",
       "    9 │ (Bool[0, 0, 0, 0, 0, 0], Bool[0,…\n",
       "   10 │ (Bool[0, 0, 0, 0, 0, 0], Bool[0,…\n",
       "   11 │ (Bool[1, 0, 0, 0, 0, 0], Bool[0,…\n",
       "  ⋮   │                 ⋮\n",
       " 1991 │ (Bool[0, 1, 0, 0, 0, 0], Bool[0,…\n",
       " 1992 │ (Bool[1, 0, 0, 0, 0, 0], Bool[0,…\n",
       " 1993 │ (Bool[1, 0, 0, 0, 0, 0], Bool[0,…\n",
       " 1994 │ (Bool[1, 0, 0, 1, 0, 0], Bool[1,…\n",
       " 1995 │ (Bool[1, 0, 0, 1, 0, 0], Bool[1,…\n",
       " 1996 │ (Bool[1, 0, 0, 1, 0, 0], Bool[1,…\n",
       " 1997 │ (Bool[1, 0, 0, 1, 0, 0], Bool[1,…\n",
       " 1998 │ (Bool[1, 0, 0, 0, 0, 0], Bool[0,…\n",
       " 1999 │ (Bool[1, 0, 0, 0, 0, 0], Bool[1,…\n",
       " 2000 │ (Bool[1, 0, 0, 0, 0, 0], Bool[1,…\n",
       "\u001b[31m                         1979 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>iteration</th><th>chain</th><th>acceptance_rate</th><th>days_to_next_predicted_purchase</th><th>hamiltonian_energy</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>200 rows × 12 columns (omitted printing of 7 columns)</p><tr><th>1</th><td>1</td><td>1</td><td>1.0</td><td>1.37874</td><td>21.8509</td></tr><tr><th>2</th><td>2</td><td>1</td><td>1.0</td><td>4.07641</td><td>15.0957</td></tr><tr><th>3</th><td>3</td><td>1</td><td>1.0</td><td>5.71715</td><td>9.18893</td></tr><tr><th>4</th><td>4</td><td>1</td><td>1.0</td><td>8.31854</td><td>7.91616</td></tr><tr><th>5</th><td>5</td><td>1</td><td>0.999205</td><td>7.2199</td><td>7.3525</td></tr><tr><th>6</th><td>6</td><td>1</td><td>1.0</td><td>11.8225</td><td>7.58637</td></tr><tr><th>7</th><td>7</td><td>1</td><td>1.0</td><td>8.66177</td><td>7.22491</td></tr><tr><th>8</th><td>8</td><td>1</td><td>1.0</td><td>9.47284</td><td>7.06928</td></tr><tr><th>9</th><td>9</td><td>1</td><td>0.999398</td><td>8.01086</td><td>7.16072</td></tr><tr><th>10</th><td>10</td><td>1</td><td>0.992705</td><td>19.3259</td><td>9.22283</td></tr><tr><th>11</th><td>11</td><td>1</td><td>1.0</td><td>14.1054</td><td>9.56028</td></tr><tr><th>12</th><td>12</td><td>1</td><td>0.991303</td><td>4.7155</td><td>9.8923</td></tr><tr><th>13</th><td>13</td><td>1</td><td>1.0</td><td>6.40599</td><td>8.60139</td></tr><tr><th>14</th><td>14</td><td>1</td><td>0.998859</td><td>5.54836</td><td>8.13662</td></tr><tr><th>15</th><td>15</td><td>1</td><td>1.0</td><td>5.65508</td><td>8.32777</td></tr><tr><th>16</th><td>16</td><td>1</td><td>1.0</td><td>8.86628</td><td>7.97622</td></tr><tr><th>17</th><td>17</td><td>1</td><td>0.999718</td><td>12.0781</td><td>7.22928</td></tr><tr><th>18</th><td>18</td><td>1</td><td>1.0</td><td>9.03118</td><td>7.20782</td></tr><tr><th>19</th><td>19</td><td>1</td><td>0.999942</td><td>8.85645</td><td>7.06562</td></tr><tr><th>20</th><td>20</td><td>1</td><td>0.999693</td><td>8.19931</td><td>7.14217</td></tr><tr><th>21</th><td>21</td><td>1</td><td>0.983261</td><td>23.7124</td><td>10.7206</td></tr><tr><th>22</th><td>22</td><td>1</td><td>1.0</td><td>12.2768</td><td>10.9452</td></tr><tr><th>23</th><td>23</td><td>1</td><td>0.9906</td><td>19.0171</td><td>8.99959</td></tr><tr><th>24</th><td>24</td><td>1</td><td>1.0</td><td>13.1287</td><td>9.16857</td></tr><tr><th>25</th><td>25</td><td>1</td><td>0.998341</td><td>14.6708</td><td>7.832</td></tr><tr><th>26</th><td>26</td><td>1</td><td>0.995499</td><td>17.5793</td><td>9.06268</td></tr><tr><th>27</th><td>27</td><td>1</td><td>1.0</td><td>7.75418</td><td>8.7589</td></tr><tr><th>28</th><td>28</td><td>1</td><td>1.0</td><td>8.83522</td><td>7.21419</td></tr><tr><th>29</th><td>29</td><td>1</td><td>0.99838</td><td>6.70334</td><td>7.493</td></tr><tr><th>30</th><td>30</td><td>1</td><td>1.0</td><td>14.5174</td><td>8.37813</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& iteration & chain & acceptance\\_rate & days\\_to\\_next\\_predicted\\_purchase & hamiltonian\\_energy & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & 1.0 & 1.37874 & 21.8509 & $\\dots$ \\\\\n",
       "\t2 & 2 & 1 & 1.0 & 4.07641 & 15.0957 & $\\dots$ \\\\\n",
       "\t3 & 3 & 1 & 1.0 & 5.71715 & 9.18893 & $\\dots$ \\\\\n",
       "\t4 & 4 & 1 & 1.0 & 8.31854 & 7.91616 & $\\dots$ \\\\\n",
       "\t5 & 5 & 1 & 0.999205 & 7.2199 & 7.3525 & $\\dots$ \\\\\n",
       "\t6 & 6 & 1 & 1.0 & 11.8225 & 7.58637 & $\\dots$ \\\\\n",
       "\t7 & 7 & 1 & 1.0 & 8.66177 & 7.22491 & $\\dots$ \\\\\n",
       "\t8 & 8 & 1 & 1.0 & 9.47284 & 7.06928 & $\\dots$ \\\\\n",
       "\t9 & 9 & 1 & 0.999398 & 8.01086 & 7.16072 & $\\dots$ \\\\\n",
       "\t10 & 10 & 1 & 0.992705 & 19.3259 & 9.22283 & $\\dots$ \\\\\n",
       "\t11 & 11 & 1 & 1.0 & 14.1054 & 9.56028 & $\\dots$ \\\\\n",
       "\t12 & 12 & 1 & 0.991303 & 4.7155 & 9.8923 & $\\dots$ \\\\\n",
       "\t13 & 13 & 1 & 1.0 & 6.40599 & 8.60139 & $\\dots$ \\\\\n",
       "\t14 & 14 & 1 & 0.998859 & 5.54836 & 8.13662 & $\\dots$ \\\\\n",
       "\t15 & 15 & 1 & 1.0 & 5.65508 & 8.32777 & $\\dots$ \\\\\n",
       "\t16 & 16 & 1 & 1.0 & 8.86628 & 7.97622 & $\\dots$ \\\\\n",
       "\t17 & 17 & 1 & 0.999718 & 12.0781 & 7.22928 & $\\dots$ \\\\\n",
       "\t18 & 18 & 1 & 1.0 & 9.03118 & 7.20782 & $\\dots$ \\\\\n",
       "\t19 & 19 & 1 & 0.999942 & 8.85645 & 7.06562 & $\\dots$ \\\\\n",
       "\t20 & 20 & 1 & 0.999693 & 8.19931 & 7.14217 & $\\dots$ \\\\\n",
       "\t21 & 21 & 1 & 0.983261 & 23.7124 & 10.7206 & $\\dots$ \\\\\n",
       "\t22 & 22 & 1 & 1.0 & 12.2768 & 10.9452 & $\\dots$ \\\\\n",
       "\t23 & 23 & 1 & 0.9906 & 19.0171 & 8.99959 & $\\dots$ \\\\\n",
       "\t24 & 24 & 1 & 1.0 & 13.1287 & 9.16857 & $\\dots$ \\\\\n",
       "\t25 & 25 & 1 & 0.998341 & 14.6708 & 7.832 & $\\dots$ \\\\\n",
       "\t26 & 26 & 1 & 0.995499 & 17.5793 & 9.06268 & $\\dots$ \\\\\n",
       "\t27 & 27 & 1 & 1.0 & 7.75418 & 8.7589 & $\\dots$ \\\\\n",
       "\t28 & 28 & 1 & 1.0 & 8.83522 & 7.21419 & $\\dots$ \\\\\n",
       "\t29 & 29 & 1 & 0.99838 & 6.70334 & 7.493 & $\\dots$ \\\\\n",
       "\t30 & 30 & 1 & 1.0 & 14.5174 & 8.37813 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m200×12 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m iteration \u001b[0m\u001b[1m chain \u001b[0m\u001b[1m acceptance_rate \u001b[0m\u001b[1m days_to_next_predicted_purchase \u001b[0m\u001b[1m ham\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64     \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64         \u001b[0m\u001b[90m Float64                         \u001b[0m\u001b[90m Flo\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │         1      1         1.0                               1.37874      ⋯\n",
       "   2 │         2      1         1.0                               4.07641\n",
       "   3 │         3      1         1.0                               5.71715\n",
       "   4 │         4      1         1.0                               8.31854\n",
       "   5 │         5      1         0.999205                          7.2199       ⋯\n",
       "   6 │         6      1         1.0                              11.8225\n",
       "   7 │         7      1         1.0                               8.66177\n",
       "   8 │         8      1         1.0                               9.47284\n",
       "   9 │         9      1         0.999398                          8.01086      ⋯\n",
       "  10 │        10      1         0.992705                         19.3259\n",
       "  11 │        11      1         1.0                              14.1054\n",
       "  ⋮  │     ⋮        ⋮           ⋮                        ⋮                     ⋱\n",
       " 191 │       191      1         0.997137                          6.0513\n",
       " 192 │       192      1         0.998443                          5.01075      ⋯\n",
       " 193 │       193      1         1.0                               7.90728\n",
       " 194 │       194      1         1.0                               9.12824\n",
       " 195 │       195      1         1.0                               9.19534\n",
       " 196 │       196      1         0.999985                         10.9798       ⋯\n",
       " 197 │       197      1         1.0                              10.8787\n",
       " 198 │       198      1         0.997995                          6.82428\n",
       " 199 │       199      1         0.99801                           5.32214\n",
       " 200 │       200      1         1.0                               6.78025      ⋯\n",
       "\u001b[31m                                                  8 columns and 179 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltv_df = DataFrame(chain_ltv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltv_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chains MCMC chain (200×10×1 Array{Float64,3}):\n",
       "\n",
       "Iterations        = 1:200\n",
       "Thinning interval = 1\n",
       "Chains            = 1\n",
       "Samples per chain = 200\n",
       "parameters        = days_to_next_predicted_purchase\n",
       "internals         = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, n_steps, nom_step_size, step_size\n",
       "\n",
       "Summary Statistics\n",
       " \u001b[1m                      parameters \u001b[0m \u001b[1m    mean \u001b[0m \u001b[1m     std \u001b[0m \u001b[1m naive_se \u001b[0m \u001b[1m    mcse \u001b[0m \u001b[1m  \u001b[0m ⋯\n",
       " \u001b[90m                          Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m  Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m  \u001b[0m ⋯\n",
       "\n",
       "  days_to_next_predicted_purchase    9.3565    3.9885     0.2820    0.2072   1 ⋯\n",
       "\u001b[31m                                                               2 columns omitted\u001b[0m\n",
       "\n",
       "Quantiles\n",
       " \u001b[1m                      parameters \u001b[0m \u001b[1m    2.5% \u001b[0m \u001b[1m   25.0% \u001b[0m \u001b[1m   50.0% \u001b[0m \u001b[1m   75.0% \u001b[0m \u001b[1m   \u001b[0m ⋯\n",
       " \u001b[90m                          Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Fl\u001b[0m ⋯\n",
       "\n",
       "  days_to_next_predicted_purchase    3.6326    6.6516    8.5672   11.4335   18 ⋯\n",
       "\u001b[31m                                                                1 column omitted\u001b[0m\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_ltv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plot(...)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
