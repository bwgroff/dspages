<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Item Response Models | Brad Groff</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Item Response Models" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Hi there!" />
<meta property="og:description" content="Hi there!" />
<link rel="canonical" href="http://www.bwg.is/julia/turing/itemresponse/2021/01/05/Item-Response-Models.html" />
<meta property="og:url" content="http://www.bwg.is/julia/turing/itemresponse/2021/01/05/Item-Response-Models.html" />
<meta property="og:site_name" content="Brad Groff" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-01-05T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"http://www.bwg.is/julia/turing/itemresponse/2021/01/05/Item-Response-Models.html","@type":"BlogPosting","headline":"Item Response Models","dateModified":"2021-01-05T00:00:00-06:00","datePublished":"2021-01-05T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.bwg.is/julia/turing/itemresponse/2021/01/05/Item-Response-Models.html"},"description":"Hi there!","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://www.bwg.is/feed.xml" title="Brad Groff" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-17444613-2','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" /><script src="https://hypothes.is/embed.js" async></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper">
<a class="site-title" rel="author" href="/">Brad Groff</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger">
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewbox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
            </svg>
          </span>
        </label>

        <div class="trigger">
<a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a>
</div>
      </nav>
</div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Item Response Models</h1>
<p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-01-05T00:00:00-06:00" itemprop="datePublished">
        Jan 5, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      14 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i> 
      
        <a class="category-tags-link" href="/categories/#Julia">Julia</a>
         
      
        <a class="category-tags-link" href="/categories/#Turing">Turing</a>
         
      
        <a class="category-tags-link" href="/categories/#ItemResponse">ItemResponse</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/bwgroff/dspages/tree/master/_notebooks/2021-01-05-Item-Response-Models.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          
          
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-01-05-Item-Response-Models.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10.561 1.5a.016.016 0 00-.01.004L3.286 8.571A.25.25 0 003.462 9H6.75a.75.75 0 01.694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0012.538 7H9.25a.75.75 0 01-.683-1.06l2.008-4.418.003-.006a.02.02 0 00-.004-.009.02.02 0 00-.006-.006L10.56 1.5zM9.504.43a1.516 1.516 0 012.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 01-.871.354h-.302a1.25 1.25 0 01-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429z"></path></svg>
    <strong>Important: </strong>This is just a draft! I haven’t 1) finished creating reasonable data sets for each model or 2) made even one pretty picture! You’re stuck with the chain summaries for now <img class="emoji" title=":dizzy_face:" alt=":dizzy_face:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f635.png" height="20" width="20">!
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-julia"><pre><span></span><span class="k">using</span> <span class="n">Turing</span>
<span class="k">using</span> <span class="n">Bijectors</span>
<span class="k">using</span> <span class="n">Gadfly</span>
<span class="k">using</span> <span class="n">DataFrames</span><span class="p">,</span> <span class="n">DataFramesMeta</span>
<span class="n">Gadfly</span><span class="o">.</span><span class="n">set_default_plot_size</span><span class="p">(</span><span class="mi">900</span><span class="n">px</span><span class="p">,</span> <span class="mi">300</span><span class="n">px</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Item-Response">Item Response<a class="anchor-link" href="#Item-Response"> </a>
</h2>
<p>Item response models are used to simultaneously make inferences about two interacting populations. Commonly, a population of test questions and a population of test takers (students) with the result (success/failure) of each student on each question they've seen. This is an interesting problem in that even in the basic case:</p>
<ul>
<li>students have different levels of aptitude</li>
<li>questions have different levels of difficulty</li>
<li>not every student sees every question</li>
<li>not every question needs to be seen by the same number of students</li>
<li>we should be able to make relative inferences between students (resp. questions) that have no overlapping questions (resp. students)</li>
<li>the data is nonetheless fairly simple: <code>[correct (Boolean), student_id (categorical), question_id (categorical]</code>
</li>
</ul>
<p>I love these models because they're easy to extend in an intuitive way. I'm going to add a few random bells and whistles to the most vanilla version, and if you're interested the <a href="https://mc-stan.org/docs/2_18/stan-users-guide/item-response-models-section.html">Stan user guide</a> has some good content on this topic and many others.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Some-IRT-Models">Some IRT Models<a class="anchor-link" href="#Some-IRT-Models"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Vanilla-Item-Response-(aka-1PL)">Vanilla Item-Response (aka 1PL)<a class="anchor-link" href="#Vanilla-Item-Response-(aka-1PL)"> </a>
</h2>
<p>For each student $s$, we have an aptitude $\alpha_s$ and for each question $q$ we have a difficulty $\gamma_q$. The likelihood of a correct response is informed by the difference between these two quantities:</p>
$$\begin{aligned}
\alpha_s &amp;\sim \mathrm{Normal}(0,5)\\
\gamma_q &amp;\sim \mathrm{Normal}(0,5)\\
\beta_{s, q} &amp;= \mathrm{logit}^{-1}(\alpha_s - \gamma_q)\\
\mathrm{correct_{s,q}} &amp;\sim \mathrm{Bernoulli}(\beta_{s,q})\\
\end{aligned}$$
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-julia"><pre><span></span><span class="n">logit</span> <span class="o">=</span> <span class="n">bijector</span><span class="p">(</span><span class="n">Beta</span><span class="p">())</span>   <span class="c"># bijection:  (0, 1)  →  ℝ</span>
<span class="n">inv_logit</span> <span class="o">=</span> <span class="n">inv</span><span class="p">(</span><span class="n">logit</span><span class="p">)</span>     <span class="c"># bijection:       ℝ  →  (0, 1)</span>

<span class="n">student</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span>
<span class="n">question</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">correct</span> <span class="o">=</span> <span class="p">[</span>
    <span class="kc">true</span><span class="p">,</span> <span class="kc">true</span><span class="p">,</span> <span class="kc">true</span><span class="p">,</span> <span class="kc">false</span><span class="p">,</span> 
    <span class="kc">true</span><span class="p">,</span> <span class="kc">false</span><span class="p">,</span> <span class="kc">false</span><span class="p">,</span> <span class="kc">true</span><span class="p">,</span> 
    <span class="kc">false</span><span class="p">,</span> <span class="kc">false</span><span class="p">,</span> <span class="kc">false</span><span class="p">,</span> <span class="kc">true</span><span class="p">];</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Some observations on the toy data:</p>
<ul>
<li>Everyone got question 1 correct (expect this to be rated as low difficulty)</li>
<li>Everyone got question 4 wrong (high difficulty)</li>
<li>Student 1 got all tested questions correct except question 4</li>
<li>Student 3 got all tested questions incorrect except question 1</li>
<li>Question 5 was only seen by student 3 (incorrect)</li>
</ul>
<p>So, here's the model set up in Turing, and the result of the sampler below.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-julia"><pre><span></span><span class="nd">@model</span> <span class="k">function</span> <span class="n">irt_1pl</span><span class="p">(</span><span class="n">correct</span><span class="o">::</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Bool</span><span class="p">},</span> <span class="n">student</span><span class="o">::</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Int64</span><span class="p">},</span> <span class="n">question</span><span class="o">::</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Int64</span><span class="p">})</span>
    <span class="n">aptitude</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">(</span><span class="n">undef</span><span class="p">,</span> <span class="n">maximum</span><span class="p">(</span><span class="n">student</span><span class="p">))</span>
    <span class="n">difficulty</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">(</span><span class="n">undef</span><span class="p">,</span> <span class="n">maximum</span><span class="p">(</span><span class="n">question</span><span class="p">))</span>
    
    <span class="c"># priors</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">aptitude</span><span class="p">)</span>
        <span class="n">aptitude</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">end</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">difficulty</span><span class="p">)</span>
        <span class="n">difficulty</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">end</span>        
    
    <span class="n">β</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">(</span><span class="n">undef</span><span class="p">,</span> <span class="n">length</span><span class="p">(</span><span class="n">correct</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span>
        <span class="n">β</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">aptitude</span><span class="p">[</span><span class="n">student</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">-</span> <span class="n">difficulty</span><span class="p">[</span><span class="n">question</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
        <span class="n">correct</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Bernoulli</span><span class="p">(</span><span class="n">inv_logit</span><span class="p">(</span><span class="n">β</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="k">end</span>
<span class="k">end</span><span class="p">;</span>

<span class="c"># Settings of the Hamiltonian Monte Carlo (HMC) sampler.</span>
<span class="n">iterations</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">ϵ</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">τ</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

<span class="n">irt_1pl_ch</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span>
    <span class="n">irt_1pl</span><span class="p">(</span><span class="n">correct</span><span class="p">,</span> <span class="n">student</span><span class="p">,</span> <span class="n">question</span><span class="p">),</span> 
    <span class="n">HMC</span><span class="p">(</span><span class="n">ϵ</span><span class="p">,</span> <span class="n">τ</span><span class="p">),</span> <span class="n">iterations</span><span class="p">,</span> 
    <span class="n">progress</span><span class="o">=</span><span class="kc">true</span><span class="p">,</span> <span class="n">drop_warmup</span><span class="o">=</span><span class="kc">true</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre><span class="ansi-green-fg">Sampling: 100%|█████████████████████████████████████████| Time: 0:00:00</span>
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Chains MCMC chain (1000×17×1 Array{Float64,3}):

Iterations        = 1:1000
Thinning interval = 1
Chains            = 1
Samples per chain = 1000
parameters        = aptitude[1], aptitude[2], aptitude[3], difficulty[1], difficulty[2], difficulty[3], difficulty[4], difficulty[5]
internals         = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, n_steps, nom_step_size, step_size

Summary Statistics
 <span class="ansi-bold">    parameters </span> <span class="ansi-bold">    mean </span> <span class="ansi-bold">     std </span> <span class="ansi-bold"> naive_se </span> <span class="ansi-bold">    mcse </span> <span class="ansi-bold">     ess </span> <span class="ansi-bold">    rhat </span>
 <span class="ansi-black-intense-fg">        Symbol </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg">  Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span>

    aptitude[1]    3.2740    1.9350     0.0612    0.3207   22.7341    1.0402
    aptitude[2]    0.9977    2.2009     0.0696    0.5345    5.0679    1.2607
    aptitude[3]   -2.7975    3.1851     0.1007    0.9097    3.2885    1.5668
  difficulty[1]   -6.6429    4.3688     0.1382    1.3718    2.4382    2.1207
  difficulty[2]   -3.1028    2.2644     0.0716    0.5146   13.6893    1.0655
  difficulty[3]    2.0820    2.0146     0.0637    0.4029   10.0855    1.1187
  difficulty[4]    5.3785    2.3564     0.0745    0.6279   10.9535    1.0266
  difficulty[5]   -0.7591    3.7529     0.1187    1.0978    3.7110    1.4890

Quantiles
 <span class="ansi-bold">    parameters </span> <span class="ansi-bold">     2.5% </span> <span class="ansi-bold">    25.0% </span> <span class="ansi-bold">   50.0% </span> <span class="ansi-bold">   75.0% </span> <span class="ansi-bold">   97.5% </span>
 <span class="ansi-black-intense-fg">        Symbol </span> <span class="ansi-black-intense-fg">  Float64 </span> <span class="ansi-black-intense-fg">  Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span>

    aptitude[1]     0.1558     1.7989    3.0630    4.7257    6.9881
    aptitude[2]    -2.7293    -0.6033    0.8091    2.4061    5.2246
    aptitude[3]    -9.5331    -4.5425   -2.9342   -0.7317    2.7270
  difficulty[1]   -12.9759   -10.1684   -7.3905   -3.1434    2.1283
  difficulty[2]    -9.1851    -4.3815   -2.6233   -1.5957    0.3462
  difficulty[3]    -2.0318     0.6111    2.2832    3.5960    5.3615
  difficulty[4]     1.1812     3.6750    5.2200    6.9466   10.4091
  difficulty[5]    -7.9556    -2.9220   -1.3910    1.0610    8.3417
</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Interesting, the only surprise for me is that I expected a wider spread for <code>difficulty[5]</code>, but otherwise looks very reasonable!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Question-Quality-(aka-2PL)">Question Quality (aka 2PL)<a class="anchor-link" href="#Question-Quality-(aka-2PL)"> </a>
</h2>
<p>The purpose of asking questions is to probe the aptitude of the test taker, and some questions will do a much better job of guaranteeing a minimum skill level given a successful response. This is called "discrimination". Intuitively, a highly discriminating question would magnify the difference between a student's ability and the question's difficulty, so that both</p>
<ul>
<li>students with sufficient aptitude are more likely to succeed</li>
<li>students with insufficient aptitude are more likely to fail</li>
</ul>
<p>We can see that $\eta$ will accomplish this in the model below:</p>
$$\begin{aligned}
\alpha_s &amp;\sim \mathrm{Normal}(0,5)\\
\gamma_q &amp;\sim \mathrm{Normal}(0,5)\\
\eta_q &amp;\sim \mathrm{LogNormal}(0,2)\\
\beta_{s, q} &amp;= \mathrm{logit}^{-1}(\eta_q * (\alpha_s - \gamma_q))\\
\mathrm{correct_{s,q}} &amp;\sim \mathrm{Bernoulli}(\beta_{s,q})\\
\end{aligned}$$
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-julia"><pre><span></span><span class="nd">@model</span> <span class="k">function</span> <span class="n">irt_2pl</span><span class="p">(</span><span class="n">correct</span><span class="o">::</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Bool</span><span class="p">},</span> <span class="n">student</span><span class="o">::</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Int64</span><span class="p">},</span> <span class="n">question</span><span class="o">::</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Int64</span><span class="p">})</span>
    <span class="n">aptitude</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">(</span><span class="n">undef</span><span class="p">,</span> <span class="n">maximum</span><span class="p">(</span><span class="n">student</span><span class="p">))</span>
    <span class="n">difficulty</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">(</span><span class="n">undef</span><span class="p">,</span> <span class="n">maximum</span><span class="p">(</span><span class="n">question</span><span class="p">))</span>
    <span class="n">discr</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">(</span><span class="n">undef</span><span class="p">,</span> <span class="n">maximum</span><span class="p">(</span><span class="n">question</span><span class="p">))</span>
    
    <span class="c"># priors</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">aptitude</span><span class="p">)</span>
        <span class="n">aptitude</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">end</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">difficulty</span><span class="p">)</span>
        <span class="n">difficulty</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">end</span>        
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">difficulty</span><span class="p">)</span>
        <span class="n">discr</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">LogNormal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">end</span>        
    
    <span class="n">β</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">(</span><span class="n">undef</span><span class="p">,</span> <span class="n">length</span><span class="p">(</span><span class="n">correct</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span>
        <span class="n">β</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">discr</span><span class="p">[</span><span class="n">question</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">*</span> <span class="p">(</span><span class="n">aptitude</span><span class="p">[</span><span class="n">student</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">-</span> <span class="n">difficulty</span><span class="p">[</span><span class="n">question</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
        <span class="n">correct</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Bernoulli</span><span class="p">(</span><span class="n">inv_logit</span><span class="p">(</span><span class="n">β</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="k">end</span>
<span class="k">end</span><span class="p">;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-julia"><pre><span></span><span class="n">irt_2pl_ch</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span>
    <span class="n">irt_2pl</span><span class="p">(</span><span class="n">correct</span><span class="p">,</span> <span class="n">student</span><span class="p">,</span> <span class="n">question</span><span class="p">),</span> 
    <span class="n">HMC</span><span class="p">(</span><span class="n">ϵ</span><span class="p">,</span> <span class="n">τ</span><span class="p">),</span> <span class="n">iterations</span><span class="p">,</span> 
    <span class="n">progress</span><span class="o">=</span><span class="kc">true</span><span class="p">,</span> <span class="n">drop_warmup</span><span class="o">=</span><span class="kc">true</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre><span class="ansi-green-fg">Sampling:  37%|███████████████▏                         |  ETA: 0:00:02</span>┌ Warning: The current proposal will be rejected due to numerical error(s).
│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)
└ @ AdvancedHMC /Users/brad/.julia/packages/AdvancedHMC/MIxdK/src/hamiltonian.jl:47
<span class="ansi-green-fg">Sampling:  38%|███████████████▋                         |  ETA: 0:00:02</span>┌ Warning: The current proposal will be rejected due to numerical error(s).
│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)
└ @ AdvancedHMC /Users/brad/.julia/packages/AdvancedHMC/MIxdK/src/hamiltonian.jl:47
<span class="ansi-green-fg">Sampling: 100%|█████████████████████████████████████████| Time: 0:00:03</span>
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Chains MCMC chain (1000×22×1 Array{Float64,3}):

Iterations        = 1:1000
Thinning interval = 1
Chains            = 1
Samples per chain = 1000
parameters        = aptitude[1], aptitude[2], aptitude[3], difficulty[1], difficulty[2], difficulty[3], difficulty[4], difficulty[5], discr[1], discr[2], discr[3], discr[4], discr[5]
internals         = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, n_steps, nom_step_size, step_size

Summary Statistics
 <span class="ansi-bold">    parameters </span> <span class="ansi-bold">    mean </span> <span class="ansi-bold">     std </span> <span class="ansi-bold"> naive_se </span> <span class="ansi-bold">    mcse </span> <span class="ansi-bold">     ess </span> <span class="ansi-bold">    rhat </span>
 <span class="ansi-black-intense-fg">        Symbol </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg">  Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span>

    aptitude[1]    1.2991    2.5842     0.0817    0.6109   15.4744    1.0188
    aptitude[2]   -0.4991    2.5806     0.0816    0.7655    4.9059    1.1926
    aptitude[3]   -1.8909    3.3642     0.1064    0.9387    6.3762    1.1386
  difficulty[1]   -2.1490    3.1013     0.0981    0.8999    3.7623    1.3383
  difficulty[2]   -3.7273    1.9332     0.0611    0.4666   14.1960    1.0006
  difficulty[3]   -3.8600    4.1205     0.1303    1.2739    2.9892    1.7147
  difficulty[4]    3.3615    2.0557     0.0650    0.4997    5.5086    1.3375
  difficulty[5]   -2.0982    3.6023     0.1139    1.0232    3.3308    1.5764
       discr[1]    4.2717   13.8163     0.4369    2.4126   24.7575    1.0508
       discr[2]    4.3264   11.0954     0.3509    1.7288   36.1833    1.0601
       discr[3]    1.1143    3.4122     0.1079    0.6271   13.4357    1.0971
       discr[4]    7.9696   12.9932     0.4109    1.7747   55.6834    1.0197
       discr[5]    2.0524    4.9542     0.1567    0.8716   17.5768    1.0340

Quantiles
 <span class="ansi-bold">    parameters </span> <span class="ansi-bold">     2.5% </span> <span class="ansi-bold">   25.0% </span> <span class="ansi-bold">   50.0% </span> <span class="ansi-bold">   75.0% </span> <span class="ansi-bold">   97.5% </span>
 <span class="ansi-black-intense-fg">        Symbol </span> <span class="ansi-black-intense-fg">  Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span>

    aptitude[1]    -2.7132   -0.5813    0.8765    2.8893    7.2904
    aptitude[2]    -4.8826   -2.5355   -0.6822    1.5337    4.2364
    aptitude[3]    -8.0107   -4.8561   -1.1829    0.8619    3.2192
  difficulty[1]   -10.9402   -3.1502   -1.5466   -0.1949    2.7139
  difficulty[2]    -8.1221   -4.9271   -3.3535   -2.3146   -0.8306
  difficulty[3]   -11.1577   -7.2108   -3.4431   -0.7276    3.0153
  difficulty[4]    -1.2933    2.1900    3.4221    4.8106    6.8774
  difficulty[5]    -7.7892   -4.9410   -2.8640    0.7741    4.9000
       discr[1]     0.0254    0.1579    0.6579    2.1601   36.1958
       discr[2]     0.0213    0.3799    0.8490    2.7462   38.2713
       discr[3]     0.0074    0.0353    0.0986    0.5403    8.5258
       discr[4]     0.0623    0.5002    2.8361   10.1297   45.3600
       discr[5]     0.0119    0.0991    0.2953    1.3438   16.8309
</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Guessing-Behavior">Guessing Behavior<a class="anchor-link" href="#Guessing-Behavior"> </a>
</h2>
<p>It's common knowledge that guessing is advantageous on the SATs if you can eliminate at least 1 answer. This is because there are usually 5 responses and an incorrect response is penalized by 1/4 point. In the previous examples we assumed that question difficulty and student aptitude accounted for a span of possible $P(\mathrm{correct})$ covering $(0,1)$, but if the test taker can opportunistically guess (ie on a multiple choice test) then the true probabilities have some other lower bound, $(\delta, 1), \delta &gt; 0$.</p>
<p>Modifying our first model to account for this is relatively straightforward:</p>
$$\begin{aligned}
\delta &amp;\sim \mathrm{Beta}(1, 2)\\
\alpha_s &amp;\sim \mathrm{Normal}(0,5)\\
\gamma_q &amp;\sim \mathrm{Normal}(0,5)\\
\beta_{s, q} &amp;= \delta + (1-\delta)\mathrm{logit}^{-1}(\alpha_s - \gamma_q)\\
\mathrm{correct_{s,q}} &amp;\sim \mathrm{Bernoulli}(\beta_{s,q})\\
\end{aligned}$$
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-julia"><pre><span></span><span class="nd">@model</span> <span class="k">function</span> <span class="n">irt_guess</span><span class="p">(</span><span class="n">correct</span><span class="o">::</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Bool</span><span class="p">},</span> <span class="n">student</span><span class="o">::</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Int64</span><span class="p">},</span> <span class="n">question</span><span class="o">::</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Int64</span><span class="p">})</span>
    <span class="n">aptitude</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">(</span><span class="n">undef</span><span class="p">,</span> <span class="n">maximum</span><span class="p">(</span><span class="n">student</span><span class="p">))</span>
    <span class="n">difficulty</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">(</span><span class="n">undef</span><span class="p">,</span> <span class="n">maximum</span><span class="p">(</span><span class="n">question</span><span class="p">))</span>
    
    <span class="c"># priors</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">aptitude</span><span class="p">)</span>
        <span class="n">aptitude</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">end</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">difficulty</span><span class="p">)</span>
        <span class="n">difficulty</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">end</span>
    <span class="n">guess_factor</span> <span class="o">~</span> <span class="n">Beta</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="n">β</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">(</span><span class="n">undef</span><span class="p">,</span> <span class="n">length</span><span class="p">(</span><span class="n">correct</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span>
        <span class="n">β</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">aptitude</span><span class="p">[</span><span class="n">student</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">-</span> <span class="n">difficulty</span><span class="p">[</span><span class="n">question</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
        <span class="n">correct</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Bernoulli</span><span class="p">(</span><span class="n">guess_factor</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">guess_factor</span><span class="p">)</span><span class="o">*</span><span class="n">inv_logit</span><span class="p">(</span><span class="n">β</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="k">end</span>
<span class="k">end</span><span class="p">;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-julia"><pre><span></span><span class="n">irt_guess_ch</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span>
    <span class="n">irt_guess</span><span class="p">(</span><span class="n">correct</span><span class="p">,</span> <span class="n">student</span><span class="p">,</span> <span class="n">question</span><span class="p">),</span> 
    <span class="n">HMC</span><span class="p">(</span><span class="n">ϵ</span><span class="p">,</span> <span class="n">τ</span><span class="p">),</span> <span class="n">iterations</span><span class="p">,</span> 
    <span class="n">progress</span><span class="o">=</span><span class="kc">true</span><span class="p">,</span> <span class="n">drop_warmup</span><span class="o">=</span><span class="kc">true</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre><span class="ansi-green-fg">Sampling: 100%|█████████████████████████████████████████| Time: 0:00:00</span>
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Chains MCMC chain (1000×18×1 Array{Float64,3}):

Iterations        = 1:1000
Thinning interval = 1
Chains            = 1
Samples per chain = 1000
parameters        = aptitude[1], aptitude[2], aptitude[3], difficulty[1], difficulty[2], difficulty[3], difficulty[4], difficulty[5], guess_factor
internals         = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, n_steps, nom_step_size, step_size

Summary Statistics
 <span class="ansi-bold">    parameters </span> <span class="ansi-bold">    mean </span> <span class="ansi-bold">     std </span> <span class="ansi-bold"> naive_se </span> <span class="ansi-bold">    mcse </span> <span class="ansi-bold">     ess </span> <span class="ansi-bold">    rhat </span>
 <span class="ansi-black-intense-fg">        Symbol </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg">  Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span>

    aptitude[1]    2.4869    2.5707     0.0813    0.7223    3.2350    1.6621
    aptitude[2]    0.0467    2.1501     0.0680    0.4649    4.9934    1.3398
    aptitude[3]   -4.6788    2.3852     0.0754    0.5883   12.5814    1.0098
  difficulty[1]   -5.4882    3.0988     0.0980    0.7927   11.2340    1.0712
  difficulty[2]   -1.3732    1.8141     0.0574    0.3498   12.9492    1.1089
  difficulty[3]    2.2928    3.9825     0.1259    1.2095    2.8536    1.6963
  difficulty[4]    5.0951    1.9785     0.0626    0.4414    5.7468    1.2786
  difficulty[5]   -0.9364    2.5749     0.0814    0.6004   17.2439    0.9997
   guess_factor    0.2061    0.1453     0.0046    0.0167   49.5365    0.9990

Quantiles
 <span class="ansi-bold">    parameters </span> <span class="ansi-bold">     2.5% </span> <span class="ansi-bold">   25.0% </span> <span class="ansi-bold">   50.0% </span> <span class="ansi-bold">   75.0% </span> <span class="ansi-bold">   97.5% </span>
 <span class="ansi-black-intense-fg">        Symbol </span> <span class="ansi-black-intense-fg">  Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span>

    aptitude[1]    -2.7677    0.6181    2.6535    4.2176    7.0921
    aptitude[2]    -4.4554   -1.3947    0.2112    1.5970    3.9855
    aptitude[3]    -9.1785   -6.4195   -4.4813   -2.8343   -0.2408
  difficulty[1]   -10.9864   -7.4053   -5.9243   -3.7231    2.0833
  difficulty[2]    -5.1880   -2.6083   -1.2140    0.0306    1.6720
  difficulty[3]    -3.9818   -0.5712    1.5472    3.9268   11.2302
  difficulty[4]     1.4102    3.7990    5.0364    6.2808    9.6207
  difficulty[5]    -7.2441   -2.3121   -0.8704    0.7449    3.9909
   guess_factor     0.0136    0.0825    0.1808    0.3095    0.5229
</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Two-Kinds-of-Questions">Two Kinds of Questions<a class="anchor-link" href="#Two-Kinds-of-Questions"> </a>
</h2>
<p>Students aren't universally adept at answering questions of different types, so let's add that to the model! For questions of type $t_i$ (ie $t(q)=t_i$), we apply the student's aptitude from that question type.</p>
$$\begin{aligned}
\alpha_{s, t} &amp;\sim \mathrm{Normal}(0,5)\\
\gamma_q &amp;\sim \mathrm{Normal}(0,5)\\
\beta_{s, q, t} &amp;= \mathrm{logit}^{-1}(\alpha_{s,t(q)} - \gamma_q)\\
\mathrm{correct_{s,q}} &amp;\sim \mathrm{Bernoulli}(\beta_{s,q})\\
\end{aligned}$$<p>More fun (but maybe too much fun for this post <img class="emoji" title=":sweat_smile:" alt=":sweat_smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f605.png" height="20" width="20">) is that with multiple question types it would be pretty simple to bake in correlations in student aptitude across question types.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-julia"><pre><span></span><span class="n">question_types</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>

<span class="nd">@model</span> <span class="k">function</span> <span class="n">irt_2types</span><span class="p">(</span>
        <span class="n">correct</span><span class="o">::</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Bool</span><span class="p">},</span> 
        <span class="n">student</span><span class="o">::</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Int64</span><span class="p">},</span> 
        <span class="n">question</span><span class="o">::</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Int64</span><span class="p">},</span> <span class="n">question_type</span><span class="o">::</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Int64</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">aptitude_1</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">(</span><span class="n">undef</span><span class="p">,</span> <span class="n">maximum</span><span class="p">(</span><span class="n">student</span><span class="p">))</span>
    <span class="n">aptitude_2</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">(</span><span class="n">undef</span><span class="p">,</span> <span class="n">maximum</span><span class="p">(</span><span class="n">student</span><span class="p">))</span>
    <span class="n">difficulty</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">(</span><span class="n">undef</span><span class="p">,</span> <span class="n">maximum</span><span class="p">(</span><span class="n">question</span><span class="p">))</span>
    
    <span class="c"># priors</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">aptitude_1</span><span class="p">)</span>
        <span class="n">aptitude_1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
        <span class="n">aptitude_2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">end</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">difficulty</span><span class="p">)</span>
        <span class="n">difficulty</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">end</span>
    
    <span class="n">β</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">(</span><span class="n">undef</span><span class="p">,</span> <span class="n">length</span><span class="p">(</span><span class="n">correct</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">question_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
            <span class="n">β</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">aptitude_1</span><span class="p">[</span><span class="n">student</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">-</span> <span class="n">difficulty</span><span class="p">[</span><span class="n">question</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
        <span class="k">else</span>
            <span class="n">β</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">aptitude_2</span><span class="p">[</span><span class="n">student</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">-</span> <span class="n">difficulty</span><span class="p">[</span><span class="n">question</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
        <span class="k">end</span>
        <span class="n">correct</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Bernoulli</span><span class="p">(</span><span class="n">inv_logit</span><span class="p">(</span><span class="n">β</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="k">end</span>
<span class="k">end</span><span class="p">;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-julia"><pre><span></span><span class="n">irt_2types_ch</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span>
    <span class="n">irt_2types</span><span class="p">(</span><span class="n">correct</span><span class="p">,</span> <span class="n">student</span><span class="p">,</span> <span class="n">question</span><span class="p">,</span> <span class="n">question_types</span><span class="p">),</span> 
    <span class="n">HMC</span><span class="p">(</span><span class="n">ϵ</span><span class="p">,</span> <span class="n">τ</span><span class="p">),</span> <span class="n">iterations</span><span class="p">,</span> 
    <span class="n">progress</span><span class="o">=</span><span class="kc">true</span><span class="p">,</span> <span class="n">drop_warmup</span><span class="o">=</span><span class="kc">true</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre><span class="ansi-green-fg">Sampling: 100%|█████████████████████████████████████████| Time: 0:00:00</span>
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Chains MCMC chain (1000×20×1 Array{Float64,3}):

Iterations        = 1:1000
Thinning interval = 1
Chains            = 1
Samples per chain = 1000
parameters        = aptitude_1[1], aptitude_1[2], aptitude_1[3], aptitude_2[1], aptitude_2[2], aptitude_2[3], difficulty[1], difficulty[2], difficulty[3], difficulty[4], difficulty[5]
internals         = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, n_steps, nom_step_size, step_size

Summary Statistics
 <span class="ansi-bold">    parameters </span> <span class="ansi-bold">    mean </span> <span class="ansi-bold">     std </span> <span class="ansi-bold"> naive_se </span> <span class="ansi-bold">    mcse </span> <span class="ansi-bold">     ess </span> <span class="ansi-bold">    rhat </span>
 <span class="ansi-black-intense-fg">        Symbol </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg">  Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span>

  aptitude_1[1]    4.1125    2.8127     0.0889    0.7651   12.7687    1.0016
  aptitude_1[2]    2.0198    2.9273     0.0926    0.7668    4.0284    1.4551
  aptitude_1[3]   -4.7104    2.8762     0.0910    0.8053    6.7425    1.0645
  aptitude_2[1]    3.2786    3.0173     0.0954    0.7514    5.4254    1.2778
  aptitude_2[2]   -0.6002    2.5990     0.0822    0.7241    5.6558    1.1660
  aptitude_2[3]    1.9599    3.2568     0.1030    0.8387   10.0610    1.1281
  difficulty[1]   -2.7944    3.3292     0.1053    0.8177   14.5871    1.0535
  difficulty[2]   -3.8994    3.5653     0.1127    1.0350    2.7201    1.9978
  difficulty[3]    0.7524    2.8349     0.0896    0.8140    8.2372    1.0174
  difficulty[4]    9.5894    3.2614     0.1031    0.8923    3.0798    1.6956
  difficulty[5]   -2.1624    3.0569     0.0967    0.8869    5.3197    1.1394

Quantiles
 <span class="ansi-bold">    parameters </span> <span class="ansi-bold">     2.5% </span> <span class="ansi-bold">   25.0% </span> <span class="ansi-bold">   50.0% </span> <span class="ansi-bold">   75.0% </span> <span class="ansi-bold">   97.5% </span>
 <span class="ansi-black-intense-fg">        Symbol </span> <span class="ansi-black-intense-fg">  Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span>

  aptitude_1[1]    -0.7504    2.0848    4.1293    5.5508   10.6943
  aptitude_1[2]    -3.0840   -0.3602    1.8441    4.4293    7.2316
  aptitude_1[3]    -9.6865   -6.8462   -5.0387   -2.2494    0.4745
  aptitude_2[1]    -1.0901    0.8448    2.8353    5.0615    9.8895
  aptitude_2[2]    -5.0098   -2.5673   -1.0476    1.4656    4.3434
  aptitude_2[3]    -3.6354   -0.6446    1.8742    4.6117    7.8919
  difficulty[1]    -8.3563   -5.2372   -3.3224   -0.2932    3.9075
  difficulty[2]   -10.8610   -6.4562   -3.6604   -0.9632    2.1568
  difficulty[3]    -4.5461   -1.2926    0.4437    2.8840    6.4110
  difficulty[4]     3.5535    7.4417    9.4532   11.5941   16.2606
  difficulty[5]    -6.8662   -4.6146   -2.6714    0.1172    3.9333
</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Test-taker-Fatigue">Test-taker Fatigue<a class="anchor-link" href="#Test-taker-Fatigue"> </a>
</h2>
<p>Imagine the test is several hours long. The test taker is pretty likely to perform differently (let's assume worse) by the end of the test, and that fatigue factor is probably pretty specific to the person. Thus, for the $i^{th}$ question we introduce a linear penalty as a first stab at the idea:</p>
$$\begin{aligned}
\alpha_s &amp;\sim \mathrm{Normal}(0,5)\\
\phi_s &amp;\sim \mathrm{LogNormal}(0,1)\\
\gamma_q &amp;\sim \mathrm{Normal}(0,5)\\
\beta_{s, q, i} &amp;= \mathrm{logit}^{-1}(\alpha_s - \gamma_q - i\phi_s)\\
\mathrm{correct_{s,q,i}} &amp;\sim \mathrm{Bernoulli}(\beta_{s,q,i})\\
\end{aligned}$$
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-julia"><pre><span></span><span class="n">question_seq</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span>
<span class="nd">@model</span> <span class="k">function</span> <span class="n">irt_fatigue</span><span class="p">(</span>
        <span class="n">correct</span><span class="o">::</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Bool</span><span class="p">},</span> <span class="n">student</span><span class="o">::</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Int64</span><span class="p">},</span> 
        <span class="n">question</span><span class="o">::</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Int64</span><span class="p">},</span> <span class="n">question_seq</span><span class="o">::</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Int64</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">aptitude</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">(</span><span class="n">undef</span><span class="p">,</span> <span class="n">maximum</span><span class="p">(</span><span class="n">student</span><span class="p">))</span>
    <span class="n">wimpiness</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">(</span><span class="n">undef</span><span class="p">,</span> <span class="n">maximum</span><span class="p">(</span><span class="n">student</span><span class="p">))</span>
    <span class="n">difficulty</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">(</span><span class="n">undef</span><span class="p">,</span> <span class="n">maximum</span><span class="p">(</span><span class="n">question</span><span class="p">))</span>
    
    <span class="c"># priors</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">aptitude</span><span class="p">)</span>
        <span class="n">aptitude</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
        <span class="n">wimpiness</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">LogNormal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">end</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">difficulty</span><span class="p">)</span>
        <span class="n">difficulty</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">end</span>        
    
    <span class="n">β</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">(</span><span class="n">undef</span><span class="p">,</span> <span class="n">length</span><span class="p">(</span><span class="n">correct</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span>
        <span class="n">β</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">aptitude</span><span class="p">[</span><span class="n">student</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">-</span> <span class="n">difficulty</span><span class="p">[</span><span class="n">question</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">-</span> <span class="n">wimpiness</span><span class="p">[</span><span class="n">student</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">*</span> <span class="n">i</span> <span class="o">*</span> <span class="n">question_seq</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">correct</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">Bernoulli</span><span class="p">(</span><span class="n">inv_logit</span><span class="p">(</span><span class="n">β</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="k">end</span>
<span class="k">end</span><span class="p">;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-julia"><pre><span></span><span class="n">irt_fatigue_ch</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span>
    <span class="n">irt_fatigue</span><span class="p">(</span><span class="n">correct</span><span class="p">,</span> <span class="n">student</span><span class="p">,</span> <span class="n">question</span><span class="p">,</span> <span class="n">question_seq</span><span class="p">),</span> 
    <span class="n">HMC</span><span class="p">(</span><span class="n">ϵ</span><span class="p">,</span> <span class="n">τ</span><span class="p">),</span> <span class="n">iterations</span><span class="p">,</span> 
    <span class="n">progress</span><span class="o">=</span><span class="kc">true</span><span class="p">,</span> <span class="n">drop_warmup</span><span class="o">=</span><span class="kc">true</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre><span class="ansi-green-fg">Sampling: 100%|█████████████████████████████████████████| Time: 0:00:00</span>
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Chains MCMC chain (1000×20×1 Array{Float64,3}):

Iterations        = 1:1000
Thinning interval = 1
Chains            = 1
Samples per chain = 1000
parameters        = aptitude[1], aptitude[2], aptitude[3], difficulty[1], difficulty[2], difficulty[3], difficulty[4], difficulty[5], wimpiness[1], wimpiness[2], wimpiness[3]
internals         = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, n_steps, nom_step_size, step_size

Summary Statistics
 <span class="ansi-bold">    parameters </span> <span class="ansi-bold">    mean </span> <span class="ansi-bold">     std </span> <span class="ansi-bold"> naive_se </span> <span class="ansi-bold">    mcse </span> <span class="ansi-bold">     ess </span> <span class="ansi-bold">    rhat </span>
 <span class="ansi-black-intense-fg">        Symbol </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg">  Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span>

    aptitude[1]    5.5689    3.2672     0.1033    0.9661    5.5541    1.0900
    aptitude[2]   -0.6428    2.2023     0.0696    0.5558    5.5129    1.2839
    aptitude[3]   -2.0090    2.7835     0.0880    0.7741    6.2247    1.1309
  difficulty[1]   -7.5951    3.1442     0.0994    0.8897   10.2621    1.0804
  difficulty[2]   -3.5479    3.0344     0.0960    0.8538    2.8263    1.9409
  difficulty[3]    0.3819    2.0660     0.0653    0.4835   15.8760    1.0060
  difficulty[4]    5.3452    3.8158     0.1207    1.0966    6.8170    1.1893
  difficulty[5]   -3.1397    2.0446     0.0647    0.5193    7.1755    1.2067
   wimpiness[1]    0.3146    0.2430     0.0077    0.0457   22.9879    0.9995
   wimpiness[2]    0.0530    0.0488     0.0015    0.0073   44.2052    1.0160
   wimpiness[3]    0.0864    0.0808     0.0026    0.0220    4.2962    1.2917

Quantiles
 <span class="ansi-bold">    parameters </span> <span class="ansi-bold">     2.5% </span> <span class="ansi-bold">   25.0% </span> <span class="ansi-bold">   50.0% </span> <span class="ansi-bold">   75.0% </span> <span class="ansi-bold">   97.5% </span>
 <span class="ansi-black-intense-fg">        Symbol </span> <span class="ansi-black-intense-fg">  Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span> <span class="ansi-black-intense-fg"> Float64 </span>

    aptitude[1]    -0.0760    2.7155    5.5546    8.5856   10.8985
    aptitude[2]    -4.8763   -2.0208   -0.7854    0.5966    4.2086
    aptitude[3]    -6.2673   -4.0574   -2.2741   -0.5126    4.9629
  difficulty[1]   -13.9438   -9.4788   -7.9346   -5.4993   -0.8206
  difficulty[2]    -8.2400   -5.8861   -3.8871   -1.4654    2.6733
  difficulty[3]    -3.2067   -1.1498    0.2113    1.9139    4.7973
  difficulty[4]    -1.0724    2.2905    5.4179    8.2336   12.3365
  difficulty[5]    -6.8396   -4.4525   -3.1455   -1.9591    1.3959
   wimpiness[1]     0.0278    0.1198    0.2535    0.4515    0.9220
   wimpiness[2]     0.0016    0.0162    0.0393    0.0767    0.1814
   wimpiness[3]     0.0028    0.0211    0.0614    0.1266    0.2839
</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Note-on-the-model-specifications">Note on the model specifications<a class="anchor-link" href="#Note-on-the-model-specifications"> </a>
</h1>
<p>You might be wondering "where did these prior values come from?" or "how did Brad choose these distributions? Why Normal instead of, I dunno, t?". Good questions! The answer is I didn't think too hard and just wrote down the first thing that seemed reasonable <img class="emoji" title=":sweat_smile:" alt=":sweat_smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f605.png" height="20" width="20"> either in terms of the values ($\mathrm{logit}^{-1}(5)$ is a very high - 99-ish% - but not insurmountable level of confidence) or theoretical properties (basically, choose a simple distribution with the right domain and range).</p>
<p>Perhaps you're also wondering "what's up with the random mixing in of Greek letters?" You got me there.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Comparison-to-Collaborative-Filtering">Comparison to Collaborative Filtering<a class="anchor-link" href="#Comparison-to-Collaborative-Filtering"> </a>
</h1>
<p>Item Response may seem very similar to collaborative filtering, so it's worth highlighting the differences.</p>
<p>Collaborative filtering aims to complete a sparsely determined preferences/ratings matrix of consumer - item scores (e.g. "User 513 gave product 149 3.5 <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20">s") $M$. A common approach is alternating least squares which iteratively factors the matrix into a product-feature matrix $P$ and a customer-preference matrix $C$. The goal is to create these so that their product "accurately completes" $M$, ie if $CP = \overline{M}$ then the difference $M - \overline{M}$ is small wherever we have entries for $M$ (remember, $M$ is incomplete).</p>
<p>A key fact is that the matrix $\overline{M}$ (the list of recommendations) is the important output here, and the factors $C$ and $P$ are intriguing but not critical. This is different from Item Response where the background variables describing difficulty and aptitude for each question, student are the primary desired outputs (but we could infer $P(\mathrm{correct} | \mathrm{student\_id}, \mathrm{question\_id})$ for unseen pairings!).</p>
<p>The other distinction worth mentioning is that the IR models have enormous flexibility in how they inform the probability of success, as we've seen above. Collaborative filtering, at least with ALS, is just optimizing a matrix factorization task. Since $\overline{M} = CP$, the user-product score can only be the dot product of the product-feature vector and the customer-preference vector, it attempts to encode "how well do the consumer preferences overlap with the product features." It does not lend itself to any extensions to capture more domain-specific nuance as we did here.</p>

</div>
</div>
</div>
</div>



  </div>
<a class="u-url" href="/julia/turing/itemresponse/2021/01/05/Item-Response-Models.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Hi there!</p>
      </div>
    </div>

    <div class="social-links">
<ul class="social-media-list"></ul>
</div>

  </div>

</footer>
</body>

</html>
